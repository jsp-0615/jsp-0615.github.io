<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>多模态</title>
      <link href="/knowledgeNotes/2025/04/17/Multimodal/"/>
      <url>/knowledgeNotes/2025/04/17/Multimodal/</url>
      
        <content type="html"><![CDATA[<h2 id="定义">定义</h2><p>“模态”是指信息的表达方式，例如：</p><ul><li><strong>文本</strong>（Text）</li><li><strong>图像</strong>（Image）</li><li><strong>语音/音频</strong>（Audio）</li><li><strong>视频</strong>（Video）</li><li><strong>传感器数据</strong>（Sensor Data）</li></ul><p><strong>多模态系统</strong>就是指能同时处理并整合这些不同类型数据的系统，因为本次任务聚焦于文本和图像的多标签文本分类，所以下文将专注于从这两的实践来叙述</p><p>多模态学习涉及到多种关键技术，包括模态的<strong>表示、对齐、融合、转换</strong>以及协同学习等，这些技术有助于建立不同模态之间的对应关系，学习多模态的共享表征空间，以及利用各模态间的互补来增强语义互补</p><h2 id="对齐vs融合"><strong>对齐vs融合</strong></h2><p>对齐关注的是如何在不同模态之间建立对应关系，而融合则是关于如何将这些多模态信息有效地结合起来，以提高模型的性能</p><p>模态表示：模态表示是将不同感官或交互方式的数据转换为计算机可理解和处理的形式，以便后续的计算、分析和融合</p><p><strong>文本模态的表示方法</strong>：文本模态的表示方法有多种，如one-hot，低维空间表示（如通过神经网络模型学习得到的转换矩阵将单词或子映射到语义空间中）、词袋表示及其衍生出的n-grams词袋表示等。目前主流的文本表示方法是预训练文本模型如BERT,Word2Vec等</p><p><strong>视觉模态的表示</strong>：视觉模态分为图像模态和视频模态。图像模态的表示主要通过卷积神经网络（CNN）实现，如LeNet-5、AlexNet、VGG、GoogLeNet、ResNet等。视频模态的表示则结合了图像的空间属性和时间属性，通常由CNN和循环神经网络（RNN）或长短时记忆网络（LSTM）等模型共同处理。</p><p>**表征学习（Representation Learning）≈向量化（Embedding）**旨在从原始数据中自动提取有效特征，<em><strong>形成计算机可理解的模态表示</strong></em>，以保留关键信息并促进跨模态交互与融合。</p><h3 id="什么是多模态联合表示（Joint-Representation）？"><strong>什么是多模态联合表示（Joint Representation）？</strong></h3><p>多模态联合表示是一种将多个模态（如文本、图像、声音等）的信息<strong>共同映射到一个统一的多模态向量空间</strong>中的表示方法。</p><p>多模态联合表示通过神经网络、概率图模型将来自不同模态的数据进行融合，生成一个包含多个模态信息的统一表示。这个表示不仅保留了每个模态的关键信息，还能够在不同模态之间建立联系，从而支持跨模态的任务，如多模态情感分析、视听语音识别等</p><p><img src="/images/jointrepresentataion.png" alt="img" /></p><h3 id="什么是多模态协同表示（Coordinated-Representation）？"><strong>什么是多模态协同表示（Coordinated Representation）？</strong></h3><p>多模态协同表示是一种<strong>将多个模态的信息分别映射到各自的表示空间</strong>，但映射后的向量或表示之间需要<strong>满足一定的相关性或约束条件</strong>的方法。这种方法的核心在于确保不同模态之间的信息在协同空间内能够相互协作，共同优化模型的性能。</p><p><img src="/images/coordinatedrepresentation.png" alt="img" /></p><p><img src="/images/modalrepresentationComparsion.png" alt="image-20241004092412638" /></p><h3 id="联合表示vs协同表示"><strong>联合表示vs协同表示</strong></h3><blockquote><p>一个映射到统一的空间中，一个分别映射到各自空间，然后再建立联系/关联</p></blockquote><table><thead><tr><th>特点</th><th>说明</th></tr></thead><tbody><tr><td>表示融合</td><td>将模态A（如图像）和模态B（如文本）提取出的特征<strong>拼接/加权</strong>后送入同一个网络模块中</td></tr><tr><td>端到端训练</td><td>整个模型（图像编码器、文本编码器、融合层、分类头）可以<strong>一起训练</strong></td></tr><tr><td>表示维度匹配</td><td>通常需要将每个模态输出投影到<strong>相同维度</strong>再融合</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">图像 ---&gt; CNN ---&gt; <span class="number">256</span>维表示 --/</span><br><span class="line">                             &gt; concat --&gt; MLP --&gt; 输出</span><br><span class="line">文本 ---&gt; BERT --&gt; <span class="number">256</span>维表示 --/</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>协同表示（Coordinated Representation）</strong>。它是多模态学习中另一个核心思路，和联合表示相比，结构更<strong>松耦合</strong>，但目的更明确——<strong>保持不同模态之间语义上的一致性，同时保留各自独立表示空间</strong>。</p><table><thead><tr><th>特征</th><th>说明</th></tr></thead><tbody><tr><td><strong>保持独立</strong></td><td>图像、文本、音频等模态分别编码，不做 early fusion</td></tr><tr><td><strong>语义对齐</strong></td><td>用“距离函数”或“对比损失”来让不同模态表示趋于一致</td></tr><tr><td><strong>可扩展性强</strong></td><td>更适合跨模态检索、生成等任务</td></tr><tr><td><strong>常结合对比学习（Contrastive Learning）</strong></td><td>如 CLIP、ALIGN 等模型中广泛使用</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment">#协同表示的示例代码</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CoordinatedModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_encoder, txt_encoder</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.img_encoder = img_encoder</span><br><span class="line">        <span class="variable language_">self</span>.txt_encoder = txt_encoder</span><br><span class="line">        <span class="variable language_">self</span>.temp = nn.Parameter(torch.tensor(<span class="number">1.0</span>))  <span class="comment"># 可学习的温度参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, images, texts</span>):</span><br><span class="line">        img_feat = F.normalize(<span class="variable language_">self</span>.img_encoder(images), dim=-<span class="number">1</span>)</span><br><span class="line">        txt_feat = F.normalize(<span class="variable language_">self</span>.txt_encoder(texts), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        logits = img_feat @ txt_feat.T / <span class="variable language_">self</span>.temp</span><br><span class="line">        labels = torch.arange(images.size(<span class="number">0</span>)).to(images.device)</span><br><span class="line"></span><br><span class="line">        loss_i2t = F.cross_entropy(logits, labels)  <span class="comment"># 图→文</span></span><br><span class="line">        loss_t2i = F.cross_entropy(logits.T, labels)  <span class="comment"># 文→图</span></span><br><span class="line">        loss = (loss_i2t + loss_t2i) / <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"><span class="comment">#联合表示的示例代码</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiModalModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 图像编码器（使用预训练的 ResNet18）</span></span><br><span class="line">        <span class="variable language_">self</span>.image_encoder = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.image_encoder.fc = nn.Linear(<span class="number">512</span>, <span class="number">256</span>)  <span class="comment"># ✅ 将原始输出映射到256维向量（统一维度）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 文本编码器（使用预训练的 BERT）</span></span><br><span class="line">        <span class="variable language_">self</span>.text_encoder = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.text_proj = nn.Linear(<span class="number">768</span>, <span class="number">256</span>)  <span class="comment"># ✅ BERT 的输出是768维，我们也把它映射到256维</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 融合+分类器（典型的联合表示结构）</span></span><br><span class="line">        <span class="variable language_">self</span>.classifier = nn.Sequential(</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span> * <span class="number">2</span>, <span class="number">128</span>),  <span class="comment"># ✅ 图像和文本各256维，拼接后是512维</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">1</span>)  <span class="comment"># ✅ 输出一个数，用于二分类（可用 sigmoid）</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image, text_input</span>):</span><br><span class="line">        <span class="comment"># 图像编码：从 ResNet 得到图像的表征</span></span><br><span class="line">        img_feat = <span class="variable language_">self</span>.image_encoder(image)  <span class="comment"># (batch_size, 256)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 文本编码：从 BERT 得到文本的语义表示（pooler_output 是[CLS] token的输出）</span></span><br><span class="line">        text_feat = <span class="variable language_">self</span>.text_encoder(**text_input).pooler_output  <span class="comment"># (batch_size, 768)</span></span><br><span class="line">        text_feat = <span class="variable language_">self</span>.text_proj(text_feat)  <span class="comment"># ✅ 投影到256维</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 联合表示融合方式：直接拼接两个模态向量</span></span><br><span class="line">        fused = torch.cat([img_feat, text_feat], dim=<span class="number">1</span>)  <span class="comment"># (batch_size, 512)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分类输出</span></span><br><span class="line">        output = <span class="variable language_">self</span>.classifier(fused)  <span class="comment"># (batch_size, 1)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="多模态对齐">多模态对齐</h3><p>对齐是指在不同模态的数据之间<strong>发现和建立对应关系</strong>的过程</p><p><strong>显示对齐（Explicit Alignment）</strong></p><p>直接建立不同模态之间得对应关系，包括无监督对齐和监督对齐，显示对齐得一个重要工作是相似性度量，大多数方法都依赖于度量不同模态之间的相似性作为基本构建块。</p><p><em><strong>无监督对齐</strong></em>：利用数据本身得统计特性或结构信息，无需额外标签，<strong>自动发现不同模态间得对应关系</strong></p><ul><li>CCA（典型相关分析）：通过最大化两组变量之间的相关性来发现它们之间的线性关系，常用于图像和文本的无监督对齐。</li><li>自编码器：通过编码-解码结构学习数据的低维表示，有时结合循环一致性损失（Cycle Consistency Loss）来实现无监督的图像-文本对齐。</li></ul><p><em><strong>监督对齐</strong></em>：利用额外得标签或监督信息指导对齐过程，确保对齐得准确性</p><ul><li>多模态嵌入模型：如DeViSE(Deep Visual-Semantic Embeddings)通过最大化图像和对应文本标签在嵌入空间中得相似度来实现监督对齐</li><li>多任务学习模型：同时学习图像分类和文本生成任务，利用共享层或联合损失函数来促进图像和文本之间得监督对齐</li></ul><p><strong>隐式对齐（Implicit Alignment）</strong></p><p>隐式对齐<strong>用作另一个任务的中间(通常是潜在的)步骤。</strong> 这允许在许多任务中有更好的表现，包括语音识别、机器翻译、媒体描述和视觉问题回答。这些模型不显式地对齐数据，也不依赖于监督对齐示例，而是学习如何在模型训练期间潜在地对齐数据。不是直接建立对应关系，而是通过模型内部机制隐式地实现跨模态的对齐，这其中就包括<strong>注意力对齐和语义对齐</strong></p><ol><li>注意力对齐<ol><li>Transformer模型：在跨模态任务中（如图像描述生成），利用自注意力机制和编码器-解码器结构，自动学习图像和文本之间的注意力分布，实现隐式对齐</li><li>BERT-Based模型：在问答系统或文本-图像检索中，结合BERT的预训练表示和注意力机制，隐式地对齐文本查询和图像内容</li></ol></li><li>语义对齐<ol><li>图神经网络（GNN）：在构建图像和文本之间的语义时，利用GNN学习节点（模态数据）之间的语义关系，实现隐式的语义对齐</li><li>预训练语言模型与视觉模型结合：如CLIP(Contrastive Lanugage-Image Pre-training)，通过对比学习在大量图像-文本对上训练，使模型学习到图像和文本在语义层面的对应关系，实现高效的隐式语义对齐</li></ol></li></ol><h2 id="多模态融合">多模态融合</h2><p><strong>什么是多模态融合（MultiModal Fusion）？</strong></p><p>多模态融合指的是抽取自不同模态的信息整合成一个稳定的多模态表征，能够充分利用不同模态之间的互补性。从数据处理的层次角度将多模态融合分为<strong>数据级融合、特征级融合和目标级融合。</strong></p><p><img src="/images/multimodalfusion.png" alt="image-20241004093207042" /></p><ul><li><p>数据级融合（Data-Level Fusion）：</p><ul><li>数据级融合，也称为像素级融合或原始数据融合，是在最底层的数据级别上进行融合。<strong>这种融合方式通常发生在数据预处理阶段，即将来自不同模态的原始数据直接合并或叠加在一起，形成一个新的数据集。</strong></li><li>应用场景：适用于那些原始数据之间具有高度相关性和互补性的情况，如图像和深度图的融合。</li></ul></li><li><p>特征级融合（Feature-Level Fusion）：</p><ul><li>特征级融合是在特征提取之后、决策之前进行的融合。<strong>不同模态的数据首先被分别处理，提取出各自的特征表示，然后将这些特征表示在某一特征层上进行融合。</strong>==注：特征层是指网络中输出语义特征的那一层，代表模态的抽象表示==</li><li>应用场景：广泛应用于图像分类、语音识别、情感分析等多模态任务中。</li></ul></li><li><p>目标级融合（Decision-Level Fusion）：</p><ul><li>目标级融合，也称为决策级融合或后期融合，是在各个单模态模型分别做出决策之后进行的融合。每个模态的模型首先独立地处理数据并给出自己的预测结果（如分类标签、回归值等），然后将这些预测结果进行整合以得到最终的决策结果。</li><li>应用场景：适用于那些需要综合考虑多个独立模型预测结果的场景，如多传感器数据融合、多专家意见综合等。</li></ul></li></ul><p><img src="/images/differenttypeofmultimodal" alt="img" /></p><h2 id="协同学习Co-learning">协同学习Co-learning</h2><p>在模态的表示和他们的预测模型之间转移知识，协同学习探索了从一种模态中学习的知识如何帮助在不同模态上训练的的计算模型，当其中一种模式资源有限（例如，带注释的数据）这一挑战尤其重要，辅助模态通常只参与模型得训练，不参与模型的使用</p><p><img src="/images/colearning.png" alt="img" /></p><h3 id="并行">并行</h3><p>需要训练数据集，其中来自一种模态的观察结果与来自其他模态的观察结果直接相关，例如在一个视听语音数据集中，视频和语音样本来自同一个说话者。</p><h3 id="非并行">非并行</h3><p>不需要来自不同模式的观察结果之间的直接联系，通常通过使用类别重叠来实现共同学习，例如，在零样本学习中，使用来自Wikipedia的纯文本数据集扩展传统的视觉对象识别数据集以改进视觉对象识别的泛化能力。</p><h3 id="混合">混合</h3><p>通过共享模式或数据集桥接</p><p>参考资料：</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN</title>
      <link href="/knowledgeNotes/2025/04/16/RNN/"/>
      <url>/knowledgeNotes/2025/04/16/RNN/</url>
      
        <content type="html"><![CDATA[<h1>RNN</h1><p>Recurrent Neural Network是一种具有循环结构的神经网络，能够处理序列数据，与传统的前馈神经网络不同，RNN通过将当前时刻的输出与前一时刻的状态（或叫做隐藏层）作为输入传递到下一个时刻，使得它能保留之前的信息并用于当前的决策</p><p><img src="/images/1HgAY1lLMYSANqtgTgwWeXQ.png" alt="img" /></p><p><strong>输入层</strong>：输入数据的每一时刻（如时间序列数据的每个时间步）都会传递到网络</p><p><strong>隐藏层</strong>：RNN的核心是循环结构，它将先前的隐藏状态与当前的输入结合，生成当前的隐藏状态。通常，RNN的隐藏层包含多个神经元，且它们的状态是由上一时刻的输出状态递归计算得来的。</p><p><strong>输出层</strong>：基于隐藏层的输出，生成预测结果。</p><p>假设我们有输入序列 $$x_1,x_2,…,x_T$$，RNN 每个时间步 t 会更新隐藏状态 $$h_t$$，基本公式如下：</p><p>$$h_t=\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)$$</p><p>$$\hat y_t=W_{hy}h_t+b_y $$</p><p>其中的参数有：</p><ul><li>$$W_{xh}$$：输入到隐藏层的权重（输入维度 → 隐藏维度）</li><li>$$W_{hh}$$：隐藏状态之间的权重（隐藏维度 → 隐藏维度）</li><li>$$b_h$$：隐藏层的偏置</li><li>$$W_{hy}$$：隐藏到输出的权重（隐藏维度 → 输出维度）</li><li>$$b_y$$：输出层偏置</li></ul><p>RNN的种类有以下这些：</p><p>one-to-one：简单预测</p><p>one-to-many：图像描述生成</p><p>many-to-one：分类问题，比如说：情感分析，给定一段话，输出这段话的情况是positive还是negative</p><p>第一个many-to-many：机器翻译，语言模型</p><p>第二个many-to-many：命名实体识别（NER），词性标注（POS Tagging）</p><p><img src="/images/various_rnn.png" alt="various_rnn" /></p><h2 id="反向传播">反向传播</h2><p>RNN的反向传播(Backpropagation Through Time,BPTT)是它的核心部分，核心思路是展开时间维度做反向传播，由于RNN会在每个时间步共享参数，在做反向传播时要沿着时间轴展开整个网络</p><p>设loss为总损失: $$L=\sum_{t=1}^TL_t=\sum_{t=1}^TCrossEntropy(y_t,\hat y_t)$$</p><blockquote><p>这里算损失的时候对于每个时间步都去算了交叉熵，那这里每个时间步的true label到底是什么</p></blockquote><ul><li>情况一：每个时间步都要输出(多对多) 语言模型，机器翻译等任务，比如输入序列是x=[“I”,“love”,“deep”,“learning”]那么目标输出（true label）：y=[“love”,“deep”,“learning”,“!”] 那么对于每个时间步就有一个true label了</li><li>情况二：只有最后一个时间步需要输出（多对一）比如情感分析，输入一段话，最终只有一个结果，假设输入是x=[“This”,“movie”,“is”,“great”] 整个序列的输出只有一个y=“positive”，那么只在最后一步做交叉熵</li><li>情况三：同样是many-to-many，比如命名实体识别，词性标注，每个输入词都对应一个标签。输入句子： x=[“Barack”,“Obama”,“was”,“born”]目标标签：y=[“PER”,“PER”,“O”,“O”]每个时间步就有对应的真实标签。</li></ul><p><em>公式上进行了求和是因为我们假设的是 <strong>每个时间步都有输出、有标签</strong> 的任务，比如语言建模、机器翻译、时间序列预测等。如果是 <strong>只在最后一步才预测的任务</strong>，就不需要对每个时间步计算交叉熵，只计算最后一个时间步的损失就可以了。</em></p><p>对输出层的参数求导:</p><p>$$\frac{\partial L}{\partial W_{hy}}=\sum_{t=1}^T\frac{\partial L_t }{\partial  \hat y_t}\cdot \frac{\partial \hat y_t}{\partial W_{hy}}$$</p><p>根据上面对损失的分类讨论，这里的输出层的参数求导的求和也会根据上面的不同而不同，如上面每个时间步都有输出的语言模型，机器翻译，时间序列预测，就会有多个loss，所以就要对每个时间步求导，然后加总起来，形成最终的$$W_{hy}$$的梯度</p><p>对隐藏状态权重$$W_{hh}$$的梯度</p><p>$$\frac{\partial L}{\partial W_{hh}} = \sum_{t=1}^{T} \sum_{k=1}^{t}<br />\left(<br />\frac{\partial L_t}{\partial h_t} \cdot<br />\frac{\partial h_t}{\partial h_k} \cdot<br />\frac{\partial h_k}{\partial W_{hh}}<br />\right)$$</p><p>看懂这个式子很重要！</p><p>它的含义是：</p><ul><li>当前的损失$$L_t$$ 不仅受到当前的隐藏状态 $$h_t$$ 影响</li><li>$$h_t$$ 又受到之前所有隐藏状态 $$h_{t-1}, h_{t-2}, \dots$$ 的影响</li><li>所以梯度要“<strong>沿着时间向前传递</strong>”</li></ul><p>由于 $$W_{hh}$$ 是 <strong>在所有时间步中共享的参数</strong>，所以它的总梯度是所有时间步对它的影响的 <strong>累加</strong>$$\frac{\partial L}{\partial W_{hh}} = \sum_{t=1}^{T}\frac{\partial L_t}{\partial W_{hh}} $$==注：这里的求和也是 根据RNN的不同类型而做区别，只有多对多任务需要累加和，为了更通用，下面一律以多对多任务的情况进行最复杂的情况进行解释==</p><p>关键在于$$W_{hh}$$ 这里的$$L_t$$​对他求导，为了看着方便我们将前向传播的式子抄下来：$$h_t=\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)$$</p><p>$$\hat y_t=W_{hy}h_t+b_y $$</p><p>根据链式法则$$L_t=CrossEntropy(\hat y_t,y_t)$$ 所以根据链式法则， $$\frac{\partial L_t}{\partial h_t}$$ 然后$$h_t$$又是和$$W_{hh}$$是有关系了但要注意这里还有个$$h_{t-1}$$$$W_{hh}$$会间接受到多个时间步的影响，这一影响就是从头影响到结尾，所以对$$W_{hh}$$有了内层的求和，</p><p>同理对于$$W_{xh}$$的梯度更新：</p><p>对于每一个时间步都有</p><p>$$\frac{\partial h_t}{\partial W_{xh}}=(1−h_t^2)⋅x_t^⊤$$==注：这个求导结果是基于激活函数是tanh的情况下==</p><p>然后对于每个时间步产生的loss的对他的梯度$$\frac{\partial L_t}{\partial W_{xh}} = \frac{\partial L_t}{\partial h_t} \cdot \frac{\partial h_t}{\partial W_{xh}} = \delta_t \cdot x_t^\top$$</p><p>其中$$\delta_t = \frac{\partial L_t}{\partial h_t} \odot (1 - h_t^2)$$⊙ 表示按元素乘法（Hadamard product）。$$\delta_t$$来自输出层的梯度反传到$$h_t$$，</p><p>总梯度（因为$$W_{xh}$$在每个时间步也是共享的</p><p>$$\frac{\partial L}{\partial W_{xh}} = \sum_{t=1}^{T} \delta_t \cdot x_t^\top$$ ==每一项$$\delta_t \cdot x_t^\top$$都只和当前时间步$$x_t,h_t$$有关==</p><p>自此一次反向传播，再梯度下降更新参数，一次反向传播就全部完成了</p><h2 id="优缺点">优缺点</h2><h3 id="优点">优点</h3><h4 id="处理序列数据的天然优势">处理序列数据的天然优势</h4><ul><li>RNN 最大的优点是<strong>可以处理变长序列输入</strong>，不像传统的全连接神经网络（MLP）只能处理固定维度的向量。</li><li>它能自动建模时间步之间的<strong>时序依赖关系（temporal dependency）</strong>，这是做 NLP 和时间序列任务的基础。</li></ul><h4 id="参数共享，模型紧凑">参数共享，模型紧凑</h4><ul><li>RNN 在每个时间步<strong>共享相同的网络参数（权重）</strong>，不像深层 MLP 那样每一层都有一套参数。</li><li>这大大减少了模型的参数量，提升了<strong>泛化能力和训练效率</strong>。</li></ul><h3 id="缺点">缺点</h3><h4 id="梯度消失和梯度爆炸">梯度消失和梯度爆炸</h4><p>在训练 RNN 时采用 <strong>反向传播通过时间（BPTT）</strong>，梯度要链式传播多个时间步。</p><p>如果时间步较多，梯度会连续相乘：</p><p>$$\frac{\partial h_t}{\partial h_k} = \prod_{i=k+1}^{t} \frac{\partial h_i}{\partial h_{i-1}}$$</p><ul><li>导数小于 1 → 梯度消失，模型学不到长期依赖；</li><li>导数大于 1 → 梯度爆炸，导致模型不稳定或发散。</li></ul><p>这是 RNN 最大的训练困难之一。</p><h4 id="难以捕捉长期依赖关系">难以捕捉长期依赖关系</h4><ul><li>虽然理论上可以记住长期历史信息，但实际上 RNN 更擅长捕捉<strong>短期依赖</strong>。这里的本质原因还是梯度消失，反向传播的时候是相乘的，每乘一次梯度都会变小，长时间步乘下来就接近0即梯度消失，第二个就是RNN的结构只有一个隐藏状态$$h_t$$来记忆之前的信息，这个隐藏状态每一步都会被新的输入和权重洗掉，旧信息会被“覆盖”</li><li>长时间间隔的输入（如前文主语和后文动词）常常会被“遗忘”或削弱。</li><li>所以原始 RNN 不能很好地解决如语言建模中的“长句子”问题。</li></ul><h4 id="不能并行计算，训练效率低">不能并行计算，训练效率低</h4><ul><li>RNN 是<strong>严格按时间步串行计算</strong>的：必须等 $$h_{t-1}$$ 算出来后，才能计算 $$h_t$$。</li><li>这使得 <strong>GPU 加速效果不明显，训练时间长</strong>，尤其在长序列任务中更为明显。</li><li>相比之下，Transformer 是完全并行的，效率更高。</li></ul>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL41 最长连续登录天数</title>
      <link href="/problemNotes/2025/04/15/SQL41/"/>
      <url>/problemNotes/2025/04/15/SQL41/</url>
      
        <content type="html"><![CDATA[<h1>SQL41 最长连续登录天数</h1><h2 id="描述">描述</h2><p>你正在搭建一个用户活跃度的画像，其中一个与活跃度相关的特征是“最长连续登录天数”， 请用SQL实现“2023年1月1日-2023年1月31日用户最长的连续登录天数”</p><p>登陆表 <strong>tb_dau：</strong></p><table><thead><tr><th>fdate</th><th>user_id</th></tr></thead><tbody><tr><td>2023-01-01</td><td>10000</td></tr><tr><td>2023-01-02</td><td>10000</td></tr><tr><td>2023-01-04</td><td>10000</td></tr></tbody></table><p>输出：</p><table><thead><tr><th>user_id</th><th>max_consec_days</th></tr></thead><tbody><tr><td>10000</td><td>2</td></tr></tbody></table><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> tb_dau;</span><br><span class="line"><span class="keyword">create table</span> `tb_dau` (</span><br><span class="line">    `fdate` <span class="type">date</span>,</span><br><span class="line">    `user_id` <span class="type">int</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">insert into</span> tb_dau(fdate, user_id)</span><br><span class="line"><span class="keyword">values</span> </span><br><span class="line">(<span class="string">&#x27;2023-01-01&#x27;</span>, <span class="number">10000</span>),</span><br><span class="line">(<span class="string">&#x27;2023-01-02&#x27;</span>, <span class="number">10000</span>),</span><br><span class="line">(<span class="string">&#x27;2023-01-04&#x27;</span>, <span class="number">10000</span>);</span><br><span class="line">user_id<span class="operator">|</span>max_consec_days</span><br><span class="line"><span class="number">10000</span><span class="operator">|</span><span class="number">2</span></span><br></pre></td></tr></table></figure><blockquote><p>MySQL中日期加减的函数<br />日期增加 DATE_ADD，例：date_add(‘2023-01-01’, interval 1 day) 输出 ‘2023-01-02’<br />日期减少 DATE_SUB，例：date_sub(‘2023-01-01’, interval 1 day) 输出 ‘2022-12-31’<br />日期差 DATEDIFF，例：datediff(‘2023-02-01’, ‘2023-01-01’) 输出31</p></blockquote><h2 id="答案">答案</h2>]]></content>
      
      
      <categories>
          
          <category> problemNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>因果推断</title>
      <link href="/knowledgeNotes/2025/04/14/causal-inference/"/>
      <url>/knowledgeNotes/2025/04/14/causal-inference/</url>
      
        <content type="html"><![CDATA[<h1>因果推断</h1><h2 id="因果阶梯：">因果阶梯：</h2><ol><li>Association P(y|X)</li><li>how seeing X</li></ol><h2 id="Simpson’s-Paradox-辛普森悖论">Simpson’s Paradox(辛普森悖论)</h2><p>揭示了<strong>聚合数据</strong>和<strong>分组数据</strong>之间可能存在方向相反的结论</p><p>当对不同子组分别进行分析时，一个趋势是存在的，但当将这些子组数据<strong>合并</strong>后，趋势可能<strong>消失或反转</strong>。</p><p>产生的原因： 人群分布在混淆变量上不一致，导致相关关系完全可以被扭曲</p><p>解决的方式：取决于因果图，forks的话要分层，collider的话就不要分层</p><h3 id="Ex1-：UC-Berkeley-gender-bias">Ex1 ：UC Berkeley gender bias.</h3><p>Graduate admissions to UC Berkeley(Fall 1973)</p><p>​University-level Data</p><table><thead><tr><th></th><th>Men</th><th></th><th>Women</th><th></th></tr></thead><tbody><tr><td></td><td>Applicants</td><td>Admitted</td><td>Applicants</td><td>Admitted</td></tr><tr><td>Total</td><td>8442</td><td>44%</td><td>4321</td><td>35%</td></tr></tbody></table><p>-&gt;  University-level data shows bias in favor of men</p><p>​Department level Data</p><table><thead><tr><th>Department</th><th>MEN</th><th></th><th>women</th><th></th></tr></thead><tbody><tr><td></td><td>Applicants</td><td>Admitted</td><td>Applicants</td><td>Admitted</td></tr><tr><td>A</td><td>825</td><td>62%</td><td>108</td><td>82%</td></tr><tr><td>B</td><td>560</td><td>63%</td><td>25</td><td>68%</td></tr><tr><td>C</td><td>325</td><td>37%</td><td>593</td><td>34%</td></tr><tr><td>D</td><td>417</td><td>33%</td><td>375</td><td>35%</td></tr><tr><td>E</td><td>191</td><td>28%</td><td>393</td><td>24%</td></tr><tr><td>F</td><td>373</td><td>6%</td><td>341</td><td>7%</td></tr></tbody></table><p>-&gt;  Department-level data shows bias in favor of women</p><h3 id="Ex2-Treatment-Effect">Ex2: Treatment Effect</h3><p>-&gt; Subpopulation data:</p><p>​Men</p><table><thead><tr><th></th><th>Not recovered</th><th>recovered</th><th>TOTAL</th></tr></thead><tbody><tr><td>Treat</td><td>6</td><td>81</td><td>87</td></tr><tr><td>No Treat</td><td>36</td><td>234</td><td>270</td></tr></tbody></table><p>P(Recovered|Treat)=81/87=0.93  ①</p><p>P(Recovered|No Treat)=234/270=0.87 ②</p><p>​Women</p><table><thead><tr><th></th><th>Not recovered</th><th>recovered</th><th>TOTAL</th></tr></thead><tbody><tr><td>Treat</td><td>71</td><td>192</td><td>263</td></tr><tr><td>No Treat</td><td>25</td><td>55</td><td>80</td></tr></tbody></table><p>P(Recovered|Treat)=192/263=0.73  ③</p><p>P(Recovered|No Treat)=55/80=0.69 ④</p><p>-&gt;Population Data:</p><table><thead><tr><th></th><th>Not recovered</th><th>recovered</th><th>TOTAL</th></tr></thead><tbody><tr><td>Treat</td><td>77</td><td>273</td><td>350</td></tr><tr><td>No Treat</td><td>61</td><td>289</td><td>350</td></tr></tbody></table><p>P(Recovered|Treat)=273/350=0.78 A</p><p>P(Recovered|No Treat)=289/350=0.83 B</p><p>what we observe is on the population data -&gt; A&lt;B</p><p>but on the subpopulation data -&gt; Men ①&gt;②; Women ③&gt;④</p><p>paradox: The data says if the gender is known, we consider that treatment has effect, but if the gender is unknown, the treatment doesn’t work.</p><table><thead><tr><th></th><th>X</th><th>Y</th><th>Z</th></tr></thead><tbody><tr><td>0</td><td>women</td><td>Not Recovered</td><td>No Treat</td></tr><tr><td>1</td><td>men</td><td>Recovered</td><td>Treat</td></tr></tbody></table><p>subpopulation data:</p><table><thead><tr><th>Men(X=1)</th><th></th><th>eSTIMATE PROBABILITY</th><th></th></tr></thead><tbody><tr><td>Treat(Z=1)</td><td>P(Y=1|X=1,Z=1)=0.93</td><td>①</td><td></td></tr><tr><td>NOT Treat(Z=0)</td><td>P(Y=1|X=1,Z=0)=0.87</td><td>②</td><td></td></tr></tbody></table><table><thead><tr><th>WOMEN(X=0)</th><th></th><th>eSTIMATE PROBABILITY</th><th></th></tr></thead><tbody><tr><td>Treat(Z=1)</td><td>P(Y=1|X=0,Z=1)=0.73</td><td>③</td><td></td></tr><tr><td>NOT Treat(Z=0)</td><td>P(Y=1|X=0,Z=0)=0.69</td><td>④</td><td></td></tr></tbody></table><table><thead><tr><th></th><th></th><th>eSTIMATE PROBABILITY</th><th></th></tr></thead><tbody><tr><td>Treat(Z=1)</td><td>P(Y=1|Z=1)=0.78</td><td>A</td><td></td></tr><tr><td>NOT Treat(Z=0)</td><td>P(Y=1|Z=0)=0.83</td><td>B</td><td></td></tr></tbody></table><p>P(Y=1|Z=1)=P(Y=1|X=1,Z=1)P(X=1|Z=1)+P(Y=1|X=0,Z=1)P(X=0|Z=1)</p><p>P(Y=1|Z=0)=P(Y=1|X=1,Z=0)P(X=1|Z=0)+P(Y=1|X=0,Z=0)P(X=0|Z=0)</p><p>令P(X=1|Z=1) 为q 则P(X=0|Z=1)为(1-q) $q\in(0,1)$</p><p>令P(X=1|Z=0) 为$q’$ 则P(X=0|Z=0)为(1-q’) $q’\in(0,1)$</p><p>则 A=①q+③(1-q) $q\in(0,1)$</p><p>B=②q’+④(1-q’) $q’\in(0,1)$</p><p>要使结果出现A&lt;B的情况：</p><ol><li><p>(1-q)的值大导致A的值趋向于③，是比①小的，从而导致了一个较小的A，同时(1-q)=P(X=0|Z=1)是个条件概率是讲治疗的人里面女性的概率，它大说明大多数的治疗的人是女性</p></li><li><p>同时①&lt;③，即女性无论治疗不治疗恢复都要比男性差</p></li></ol><p>同时满足这两个条件才可能出现反转的效果，即性别即会影响是否去治疗，同时也影响恢复情况</p><img src="causal-inference/image-20250414231146818.png"><h3 id="Ex3：">Ex3：</h3><p>给1500人用TreatmentA，550人用B看致死率，但本身病人的情况有轻重之分</p> <img src="causal-inference/CI_basic_1.png"><p>现象：subpopulation之后结论是B致死率更高，但是total的时候是A更好</p><p>造成的原因是unequal weighting：重症的人得到了更多得B，导致B看起来效果不好了⇒总体得结论是一个有偏的加权平均</p><ul><li>Treatment A的致死率计算里面，轻症的致死率全重大，所以致死率小</li><li>Treatment B的致死率计算里面，重症的致死率全重大，所以致死率大</li></ul><p>正确的解释：Either treatment A or treatment B could be the right answer, depending on 数据的因果结构!</p><ul><li>condition is a cause of the treatment</li></ul><div style="display: flex; justify-content: center; gap: 20px;">  <img src="causal-inference/CI_basic_2.png" style="max-width: 45%;">  <img src="causal-inference/CI_basic_3.png" style="max-width: 45%;"></div><p>​比如医生把B专门用在重症，轻症的给A就行</p><p>​选择：这种情况要选B，看（subpopulation的结论，因为我们B中的高致死率知识因为本身就有很高的致死率里面有很多的重症</p><ul><li>treatment is a cause of the condition</li></ul><div style="display: flex; justify-content: center; gap: 20px;">  <img src="causal-inference/CI_basic_4.png" style="max-width: 45%;">  <img src="causal-inference/CI_basic_5.png" style="max-width: 45%;"></div><ul><li>解释：比如如果Treatment B，必须要等很久才能take，所以在等的时候condition会worsen——变成了重症！从而导致了更多的重症被接受了Treatment B. Treatment A不用等所以马上就轻症了！这就是为什么A的轻症占比更高</li><li>选择：这种情况要选A（看total的结论），因为Treatment本身是造成worse condition的原因，从而导致了Y。所以我们需要考虑T对C的影响而不能直接看conditional的结论（因为T会让你去不同的C！）</li></ul><p>考虑这个影响的办法就是直接看T对Y的总体效果。</p><p>结论：conclusion取决于causal structure</p><h2 id="统计基础知识点">统计基础知识点</h2><p>Independence: P(A∩B)=P(A)⋅P(B)</p><p>P(A|B) = P(A) 即当A与B独立，则已知B发生A发生的概率就是A本身发生的概率，他们的发生不会互相影响</p><p>condition independence: P(A|B,C)=P(A|C)</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A/B Test</title>
      <link href="/knowledgeNotes/2025/04/14/A-B-test/"/>
      <url>/knowledgeNotes/2025/04/14/A-B-test/</url>
      
        <content type="html"><![CDATA[<h1>A/B testing</h1><h2 id=""></h2>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL44 查询连续入住多晚的客户信息？</title>
      <link href="/problemNotes/2025/04/12/SQL44/"/>
      <url>/problemNotes/2025/04/12/SQL44/</url>
      
        <content type="html"><![CDATA[<h1>SQL44查询连续入住多晚的客户信息？</h1><h2 id="描述">描述</h2><p>某酒店客房信息数据及某晚入住信息数据如下：</p><p>客房信息表<strong>guestroom_tb</strong>(room_id-房间号,room_type-房间类型,room_price-房间价格)，如下所示：</p><table><thead><tr><th>room_id</th><th>room_type</th><th>room_price</th></tr></thead><tbody><tr><td>1001</td><td>商务标准房</td><td>165</td></tr><tr><td>1002</td><td>家庭套房</td><td>376</td></tr><tr><td>1003</td><td>商务单人房</td><td>100</td></tr><tr><td>1004</td><td>商务单人房</td><td>100</td></tr><tr><td>1005</td><td>商务标准房</td><td>165</td></tr><tr><td>1006</td><td>商务单人房</td><td>100</td></tr><tr><td>1007</td><td>商务标准房</td><td>165</td></tr><tr><td>1008</td><td>家庭套房</td><td>365</td></tr><tr><td>1009</td><td>商务标准房</td><td>165</td></tr></tbody></table><p>入住信息表<strong>checkin_tb</strong>(info_id-信息id.room_id-房间号,user_id-客户id,checkin_time-入住时间,checkout_time-退房时间)，</p><p>该表存储该晚客户入住信息及后续退房信息，如下所示：</p><table><thead><tr><th>info_id</th><th>room_id</th><th>user_id</th><th>checkin_time</th><th>checkout_time</th></tr></thead><tbody><tr><td>1</td><td>1001</td><td>201</td><td>2022-06-12 15:00:00</td><td>2022-06-13 09:00:00</td></tr><tr><td>2</td><td>1001</td><td>202</td><td>2022-06-12 15:00:00</td><td>2022-06-13 09:00:00</td></tr><tr><td>3</td><td>1003</td><td>203</td><td>2022-06-12 14:00:00</td><td>2022-06-14 08:00:00</td></tr><tr><td>4</td><td>1004</td><td>204</td><td>2022-06-12 15:00:00</td><td>2022-06-13 11:00:00</td></tr><tr><td>5</td><td>1007</td><td>205</td><td>2022-06-12 16:00:00</td><td>2022-06-15 12:00:00</td></tr><tr><td>6</td><td>1008</td><td>206</td><td>2022-06-12 19:00:00</td><td>2022-06-13 12:00:00</td></tr><tr><td>7</td><td>1008</td><td>207</td><td>2022-06-12 19:00:00</td><td>2022-06-13 12:00:00</td></tr><tr><td>8</td><td>1009</td><td>208</td><td>2022-06-12 20:00:00</td><td>2022-06-16 09:00:00</td></tr></tbody></table><p>问题：请查询该酒店从6月12日开始连续入住多晚的客户信息？</p><p>要求输出：客户id、房间号、房间类型、连续入住天数（按照连续入住天数的升序排序，再按照房间号的升序排序，再按照客户id的降序排序）</p><p>示例数据结果如下：</p><table><thead><tr><th>user_id</th><th>room_id</th><th>room_type</th><th>days</th></tr></thead><tbody><tr><td>203</td><td>1003</td><td>商务单人房</td><td>2</td></tr><tr><td>205</td><td>1007</td><td>商务标准房</td><td>3</td></tr><tr><td>208</td><td>1009</td><td>商务标准房</td><td>4</td></tr></tbody></table><p>解释：以客户203为例，在2022-06-12入住酒店，在2022-06-14退房，连续在12日晚、13日晚入住在该酒店，故结果如上；其他结果同理。</p><p>示例输入：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span>  `guestroom_tb` ; </span><br><span class="line"><span class="keyword">CREATE TABLE</span> `guestroom_tb` (</span><br><span class="line">`room_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`room_type` <span class="type">varchar</span>(<span class="number">16</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`room_price` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line"><span class="keyword">PRIMARY KEY</span> (`room_id`));</span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1001</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1002</span>,<span class="string">&#x27;家庭套房&#x27;</span>,<span class="number">376</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1003</span>,<span class="string">&#x27;商务单人房&#x27;</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1004</span>,<span class="string">&#x27;商务单人房&#x27;</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1005</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1006</span>,<span class="string">&#x27;商务单人房&#x27;</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1007</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1008</span>,<span class="string">&#x27;家庭套房&#x27;</span>,<span class="number">365</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1009</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span>  `checkin_tb` ; </span><br><span class="line"><span class="keyword">CREATE TABLE</span> `checkin_tb` (</span><br><span class="line">`info_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`room_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`user_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`checkin_time` datetime <span class="keyword">NOT NULL</span>,</span><br><span class="line">`checkout_time` datetime <span class="keyword">NOT NULL</span>,</span><br><span class="line"><span class="keyword">PRIMARY KEY</span> (`info_id`));</span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">1</span>,<span class="number">1001</span>,<span class="number">201</span>,<span class="string">&#x27;2022-06-12 15:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 09:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">2</span>,<span class="number">1001</span>,<span class="number">202</span>,<span class="string">&#x27;2022-06-12 15:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 09:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">3</span>,<span class="number">1003</span>,<span class="number">203</span>,<span class="string">&#x27;2022-06-12 14:00:00&#x27;</span>,<span class="string">&#x27;2022-06-14 08:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">4</span>,<span class="number">1004</span>,<span class="number">204</span>,<span class="string">&#x27;2022-06-12 15:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 11:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">5</span>,<span class="number">1007</span>,<span class="number">205</span>,<span class="string">&#x27;2022-06-12 16:00:00&#x27;</span>,<span class="string">&#x27;2022-06-15 12:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">6</span>,<span class="number">1008</span>,<span class="number">206</span>,<span class="string">&#x27;2022-06-12 19:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 12:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">7</span>,<span class="number">1008</span>,<span class="number">207</span>,<span class="string">&#x27;2022-06-12 19:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 12:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">8</span>,<span class="number">1009</span>,<span class="number">208</span>,<span class="string">&#x27;2022-06-12 20:00:00&#x27;</span>,<span class="string">&#x27;2022-06-16 09:00:00&#x27;</span>);</span><br></pre></td></tr></table></figure><p>答案</p><p>这道题对我的难点在于，在group by的时候，想要输出哪些列group by的时候就要写哪些，我这里用group by是因为我怕同一个顾客有多次入住记录，比如用户201他在6月12日有过入住记录，如果它6月15号还有入住记录，这时候就需要有区别。</p><p><code>DATE(ct.checkin_time) = '2022-06-12'</code>：选择在2022年6月12日入住的记录。<code>DATEDIFF(ct.checkout_time, ct.checkin_time) &gt;= 2</code>：选择连续入住至少两晚的记录（注意不要在where直接使用days&gt;= 2）。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id,</span><br><span class="line">    g.room_id,</span><br><span class="line">    room_type,</span><br><span class="line">    <span class="keyword">day</span> (checkout_time) <span class="operator">-</span> <span class="keyword">day</span> (checkin_time) <span class="keyword">as</span> days</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            user_id,</span><br><span class="line">            c.room_id,</span><br><span class="line">            checkin_time,</span><br><span class="line">            checkout_time</span><br><span class="line">        <span class="keyword">from</span></span><br><span class="line">            checkin_tb <span class="keyword">as</span> c</span><br><span class="line">        <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">            user_id,</span><br><span class="line">            c.room_id,</span><br><span class="line">            checkin_time,</span><br><span class="line">            checkout_time</span><br><span class="line">    ) temp</span><br><span class="line">    <span class="keyword">inner</span> <span class="keyword">join</span> guestroom_tb <span class="keyword">as</span> g <span class="keyword">on</span> g.room_id <span class="operator">=</span> temp.room_id</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    <span class="type">DATE</span> (temp.checkin_time) <span class="operator">&gt;=</span> <span class="string">&#x27;2022-06-12&#x27;</span></span><br><span class="line">    <span class="keyword">and</span> <span class="keyword">day</span> (checkout_time) <span class="operator">-</span> <span class="keyword">day</span> (checkin_time) <span class="operator">&gt;</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    days,</span><br><span class="line">    g.room_id,</span><br><span class="line">    user_id <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>题解代码</p><p>注意使用DATEDIFF函数，然后where语句不能直接使用days来做判断条件，但是我觉得题解这里没有解决同一个顾客如果有多条记录的情况怎么解决</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    ct.user_id,</span><br><span class="line">    ct.room_id,</span><br><span class="line">    gt.room_type,</span><br><span class="line">    DATEDIFF(ct.checkout_time, ct.checkin_time) <span class="keyword">AS</span> days</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    checkin_tb ct</span><br><span class="line"><span class="keyword">JOIN</span> </span><br><span class="line">    guestroom_tb gt <span class="keyword">ON</span> gt.room_id <span class="operator">=</span> ct.room_id</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">   <span class="type">DATE</span>(ct.checkin_time) <span class="operator">=</span> <span class="string">&#x27;2022-06-12&#x27;</span> <span class="keyword">AND</span> DATEDIFF(ct.checkout_time, ct.checkin_time) <span class="operator">&gt;=</span> <span class="number">2</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span></span><br><span class="line">    days <span class="keyword">ASC</span>, ct.room_id <span class="keyword">ASC</span>, ct.user_id <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> problemNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The First Blog</title>
      <link href="/knowledgeNotes/2025/04/12/my-first-blog/"/>
      <url>/knowledgeNotes/2025/04/12/my-first-blog/</url>
      
        <content type="html"><![CDATA[<h1>The first blog</h1><p>时间开始于2025/4/12，周六，晚上20:45，终于千难万险将所有前期准备弄完了！接下来我会定期将自己的学习笔记跟新在这里，一方面督促自己努力学习，同时将脑中知识整理成可以发布出去的版本！</p><h2 id="简介">简介</h2><p>嗯。。。简单介绍一下自己，我是一名悉大的学生Jasper，正在学习Data Science，但目前的就业情况呢，导致我这种学历的人呢，上不上，下不下的，所以我想以博客的形式督促增加自己的技能点，点亮所有必要的知识点，目前呢自己的状态就是啥都会一点，但是啥都不是那么会，包括最基础的Python/SQL/R，Machine Learning，Deep Learning，作为一个计算机科班出生的，Java自然也不在话下，算法嘛会点，但绝对不多，大数据框架Hadoop好像是学完了，但好像又没有，Hive，Spark现在还在学习中</p><p>最后用看到张一鸣说过的一句话来结尾</p><p>做正确的事才是务实，短期投机不是务实。大力出奇迹事务实，刨根问底是务实，抓住本之是务实，尊重用户是务实，认识世界的多样性是务实。</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
