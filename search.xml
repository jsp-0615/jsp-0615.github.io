<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Vision Transformer</title>
      <link href="/knowledgeNotes/2025/04/25/ViT/"/>
      <url>/knowledgeNotes/2025/04/25/ViT/</url>
      
        <content type="html"><![CDATA[<p>**ViT（Vision Transformer）**是将传统上处理自然语言的 Transformer 架构，<strong>直接应用到图像分类</strong>, 把图像切成很多小patch（小块），把每个patch当成一个“单词”（token），送入Transformer进行特征提取，最后用一个MLP分类器输出类别</p><p>整体分4个步骤：</p><p>(1) Image → Patch Embedding<br />(2) Add Position Encoding<br />(3) Transformer Encoder (self-attention)<br />(4) MLP Classifier</p><p><img src="/images/ViT.jpg" alt="img" /></p><h2 id="ViT基本架构">ViT基本架构</h2><h3 id="1-Patch-Embedding">1. Patch Embedding</h3><p>Transformer原本是用来做NLP的工作的，所以ViT的首要任务是将图转换成词的结构，这里采取的方法是如上图左下角所示，将图片分割成小块，每个小块就相当于句子里的一个词。这里把每个小块称作Patch，而<strong>Patch Embedding</strong>就是把每个Patch再经过一个全连接网络压缩成一定维度的向量。把图片切成小块，假设原始输入图片为(3,224,224)，将其分割成很多小块（patch），比如16x16，每个小块拉平成一个向量（flatten），然后过一个线性层形成<strong>Patch Embedding</strong></p><p>这里是ViT源代码中关于Patch Embedding的部分</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 默认img_size=224, patch_size=16，in_chans=3，embed_dim=768，</span><br><span class="line">self.patch_embed = embed_layer(</span><br><span class="line">    img_size=img_size, patch_size=patch_size, </span><br><span class="line">    in_chans=in_chans, embed_dim=embed_dim)</span><br></pre></td></tr></table></figure><p>而embed_layer其实是PatchEmbed</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 2D Image to Patch Embedding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span>, flatten=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># img_size = (img_size, img_size)</span></span><br><span class="line">        img_size = to_2tuple(img_size)</span><br><span class="line">        patch_size = to_2tuple(patch_size)</span><br><span class="line">        <span class="variable language_">self</span>.img_size = img_size</span><br><span class="line">        <span class="variable language_">self</span>.patch_size = patch_size</span><br><span class="line">        <span class="variable language_">self</span>.grid_size = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])</span><br><span class="line">        <span class="variable language_">self</span>.num_patches = <span class="variable language_">self</span>.grid_size[<span class="number">0</span>] * <span class="variable language_">self</span>.grid_size[<span class="number">1</span>]</span><br><span class="line">        <span class="variable language_">self</span>.flatten = flatten</span><br><span class="line">        <span class="comment"># 输入通道，输出通道，卷积核大小，步长</span></span><br><span class="line">        <span class="comment"># C*H*W-&gt;embed_dim*grid_size*grid_size</span></span><br><span class="line">        <span class="variable language_">self</span>.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class="line">        <span class="variable language_">self</span>.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        <span class="keyword">assert</span> H == <span class="variable language_">self</span>.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == <span class="variable language_">self</span>.img_size[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj(x)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.flatten:</span><br><span class="line">            x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># BCHW -&gt; BNC</span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>proj虽然用的是卷积的写法，但其实是将每个patch接入了同样的全连接网络，将每个patch转换成了一个向量。x的维度是（B，C，H，W）其中B是batch size，C通常是三通道，H和W分别是图片的高和宽，而输出则是（B，N，E），B依然是batch size，N则是每张图被切割成了patch之后，patch的数量，E是embed_size，每个patch会通过一个全连接网络转换成一个向量，E是这个向量的长度，根据卷积的原理，也可以理解为每个patch的特征数量。</p><h3 id="2-Positional-Embedding">2. Positional Embedding</h3><p>因为Transformer是无序的，所以要给每个patch加上位置信息，把图片分割成了patch，然后把每个patch转换成了embedding，接下来就是在embedding中加入位置信息。产生位置信息的方式主要分两大类，一类是直接通过固定算法产生，一种是训练获得。但加位置信息的方式还是比较统一且粗暴的。</p><p><img src="/images/positional_embedding_1.jpg" alt="img" /></p><p>产生一个位置向量，长度和patch embedding一致，然后直接相加。那么这个位置向量大概长下面这样</p><p><img src="/images/positional_embedding_2.jpg" alt="img" /></p><p>比如patch embedding长度为4，那么位置向量长度也为4，每个位置有一个在[-1,1]的值</p><p><img src="/images/positional_embedding_3.jpg" alt="img" /></p><p>假设你现在一张图切成了20个patch，embedding的长度是512，那么位置向量可以是上面这样的（tensor2tensor中的get_timing_signal_1d函数），每一行代表一个位置向量，第一行是位置0的位置向量，第二行是位置1的位置向量。</p><p>位置向量也可以是下面这样的：</p><p><img src="/images/positional_embedding_4.jpg" alt="img" /></p><p>公式如下：</p><p>$$PE_{(pos,2i)}=sin(pos/10000^{2i/d_model}) \ PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_model})$$</p><p>pos是单词在句子中的位置，或者patch在图中的位置，而i对应的是embedding的位置，dmodel对应的是patch embedding的长度，。这里说一下为什么要加这个位置编码，以及加上以后会有什么效果，我们观察上两幅图，可以发现，位置编码是随位置而改变的，位置差别越大的，那么向量差别也越大。在NLP里说过，把一个词转换成向量，就好像把一个词映射到了一个高维空间的位置，意思相近的词会在高维空间内比较靠近，而加上位置向量，会让位置相近的词更靠近，位置远的词离得更远。再来，为什么用cos，sin这种方式，作者的解释是，使用sin和cos编码可以得到词语之间的相对位置。</p><p>timm中对positional encoding的实现：</p><p><img src="/images/timmpositionalencoding.jpg" alt="img" /></p><p>可以发现timm中的positional encoding是随机数，也就是说没有做positional encoding，可能只是给你留了个位置，而默认的值服从某种正太分布，且限于很小的数值区间，这里就不上代码和详细解释了。至于这里为什么是随机数。一个是保留位置，便你扩展，二是本来positional encoding就有两类方式可以实现，一种是用一定的算法生成，另外一种就是通过训练调整获得。timm应该是默认是通过训练来调整获得</p><h3 id="3-Self-Attention">3. Self-Attention</h3><p>ViT中的Attention，和Transformer中的self-attention一致，参考[1]介绍self-attention，举例语义处理的例子：</p><p>“The animal didn’t cross the street because it was too tired.”</p><p>我们人很容易理解，后面的it是指animal，但是要怎么让机器能够把it和animal关联起来呢？</p><p><img src="/images/self_attention_1.jpg" alt="img" /></p><p>Self-attention就是在这种需求下产生的，如上图所示，我们应当有一个结构能够表达每个单词和其他每个单词的关系。那这里我们处理的是图像问题，Self-attention的存在就可以理解成，我们应当有一个结构能够表达每个patch和其他patch的关系。之前说过，图像中的patch和语义处理中的词可以同等来看</p><p>具体实现:</p><ol><li><p>基于输入向量创建三个向量：query向量，key向量和value向量</p><p><img src="/images/qkv1.jpg" alt="img" /></p><p>==注：$W^Q$是一个参数矩阵（权重矩阵），用于把输入的每个单词的embedding向量x线性变换成query向量q==</p></li><li><p>由query向量和key向量产生自注意力</p><p><img src="/images/qkv2.jpg" alt="img" /></p><p>Thinking和Machine可以理解为图片被切分的两个patch，现在计算Thinking的自注意力，通过q乘k，除以一定系数（<strong>scaled dot-product attention</strong>，点积得到的结果值通常很大，使得softmax结果不能很好地表达attention值。这时候除以一个缩放因子，可以一定程度上减缓这种情况。），通过softmax之后会得到一个关于Thinking的注意力向量，比如这个例子是[0.88, 0.12]，这个向量的意思是，要解释Thinking这个词在这个句子中的意思，应当取0.88份Thinking原本的意思，再取0.12份Machine原本的意思，就是Thinking在这个句子中的意思。最后图中Sum之后的结果所表达的就是每个单词在这个句子当中的意思。整个过程可以用下面这张图表达</p><p><img src="/images/qkv3.jpg" alt="img" /></p></li></ol><h3 id="4-Multi-Head-Attention">4. Multi-Head Attention</h3><p>timm中attention是在self-attention基础上改进的multihead attention，也就是在产生qkv的时候，对qkv进行切分，切分成了num_heads份，对每一份分别进行self-attention的操作，最后拼接起来，这样一定程度上进行了参数隔离，至于为什么效果会更好，大概率是因为这样操作会让关联特征集中在一起，更容易训练</p><p><img src="/images/multihead.jpg" alt="img" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads=<span class="number">8</span>, qkv_bias=<span class="literal">False</span>, attn_drop=<span class="number">0.</span>, proj_drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="comment"># q,k,v向量长度</span></span><br><span class="line">        head_dim = dim // num_heads</span><br><span class="line">        <span class="variable language_">self</span>.scale = head_dim ** -<span class="number">0.5</span></span><br><span class="line">        <span class="variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=qkv_bias)</span><br><span class="line">        <span class="variable language_">self</span>.attn_drop = nn.Dropout(attn_drop)</span><br><span class="line">        <span class="variable language_">self</span>.proj = nn.Linear(dim, dim)</span><br><span class="line">        <span class="variable language_">self</span>.proj_drop = nn.Dropout(proj_drop)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 这里C对应上面的E，向量的长度</span></span><br><span class="line">        B, N, C = x.shape</span><br><span class="line">        <span class="comment"># (B, N, C) -&gt; (3，B，num_heads, N, C//num_heads), //是向下取整的意思。</span></span><br><span class="line">        qkv = <span class="variable language_">self</span>.qkv(x).reshape(B, N, <span class="number">3</span>, <span class="variable language_">self</span>.num_heads, C // <span class="variable language_">self</span>.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="comment"># 将qkv在0维度上切成三个数据块，q,k,v:(B，num_heads, N, C//num_heads)</span></span><br><span class="line">        <span class="comment"># 这里的效果是从每个向量产生三个向量，分别是query，key和value</span></span><br><span class="line">        q, k, v = qkv.unbind(<span class="number">0</span>)   <span class="comment"># make torchscript happy (cannot use tensor as tuple)</span></span><br><span class="line">        <span class="comment"># @矩阵相乘获得score (B,num_heads,N,N)</span></span><br><span class="line">        attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * <span class="variable language_">self</span>.scale</span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        attn = <span class="variable language_">self</span>.attn_drop(attn)</span><br><span class="line">        <span class="comment"># (B,num_heads,N,N)@(B,num_heads,N,C//num_heads)-&gt;(B,num_heads,N,C//num_heads)</span></span><br><span class="line">        <span class="comment"># (B,num_heads,N,C//num_heads) -&gt;(B,N,num_heads,C//num_heads)</span></span><br><span class="line">        <span class="comment"># (B,N,num_heads,C//num_heads) -&gt; (B, N, C)</span></span><br><span class="line">        x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C)</span><br><span class="line">        <span class="comment"># (B, N, C) -&gt; (B, N, C)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.proj(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.proj_drop(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>multi-head attention总示意图如下：</p><p><img src="/images/overallmultihead.jpg" alt="img" /></p><h3 id="5-Layer-Normalization">5. Layer Normalization</h3><p>Layer normalization对应的一个概念是我们熟悉的Batch Normalization，这两个根本的不同在于，Layer normalization是对每个样本的所有特征进行归一化，而Batch Normalization是对每个通道的所有样本进行归一化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NLP Example</span></span><br><span class="line">batch, sentence_length, embedding_dim = <span class="number">20</span>, <span class="number">5</span>, <span class="number">10</span></span><br><span class="line">embedding = torch.randn(batch, sentence_length, embedding_dim)</span><br><span class="line"><span class="comment"># 指定归一化的维度</span></span><br><span class="line">layer_norm = nn.LayerNorm(embedding_dim)</span><br><span class="line"><span class="comment"># 进行归一化</span></span><br><span class="line">layer_norm(embedding)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Image Example</span></span><br><span class="line">N, C, H, W = <span class="number">20</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">10</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(N, C, H, W)</span><br><span class="line"><span class="comment"># Normalize over the last three dimensions (i.e. the channel and spatial dimensions)</span></span><br><span class="line"><span class="comment"># as shown in the image below</span></span><br><span class="line">layer_norm = nn.LayerNorm([C, H, W])</span><br><span class="line">output = layer_norm(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/layernormalization.jpg" alt="img" /></p><p>在ViT中，虽然LN处理的是图片数据，但在进行LN之前，图片已经被切割成了Patch，而每个Patch表示的是一个词，因此是在用语义的逻辑在解决视觉问题，因此在ViT中，LN也是按语义的逻辑在用的</p><h3 id="6-Drop-Path">6. Drop Path</h3><p>Dropout是最早用于解决网络过拟合的方法，是所有drop类方法的始祖。</p><p><img src="/images/dropout.jpg" alt="img" /></p><p>在向前传播的时候，让神经元以一定概率停止工作。这样可以使模型泛化能力变强，因为神经元会以一定概率失效，这样的机制会使结果不会过分依赖于个别神经元。训练阶段，以keep_prob概率使神经元失效，而推理的时候，会保留所有神经元的有效性，因此，训练时候加了dropout的神经元推理出来的结果要除以keep_prob。</p><p>接下来以dropout的思路来理解drop path</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> drop_prob == <span class="number">0.</span> <span class="keyword">or</span> <span class="keyword">not</span> training:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="comment"># drop_prob是进行droppath的概率</span></span><br><span class="line">    keep_prob = <span class="number">1</span> - drop_prob</span><br><span class="line">    <span class="comment"># work with diff dim tensors, not just 2D ConvNets</span></span><br><span class="line">    <span class="comment"># 在ViT中，shape是(B,1,1),B是batch size</span></span><br><span class="line">    shape = (x.shape[<span class="number">0</span>],) + (<span class="number">1</span>,) * (x.ndim - <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 按shape,产生0-1之间的随机向量,并加上keep_prob  </span></span><br><span class="line">    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)</span><br><span class="line">    <span class="comment"># 向下取整，二值化，这样random_tensor里1出现的概率的期望就是keep_prob</span></span><br><span class="line">    random_tensor.floor_()  <span class="comment"># binarize</span></span><br><span class="line">    <span class="comment"># 将一定图层变为0</span></span><br><span class="line">    output = x.div(keep_prob) * random_tensor</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>由代码可以看出，drop path是在batch那个维度，随机将一些图层直接变成0，以加快运算速度。</p><h3 id="Transformer-Encoder">Transformer Encoder</h3><p>Transformer架构图</p><p><img src="/images/Transformer.jpg" alt="img" /></p><p>Transformer是由一堆encoder和decoder形成的，那encoder一般的架构图如下</p><p><img src="/images/encoder.jpg" alt="img" /></p><p>输入[CLS] token + Patch Embeddings + Position Embeddings</p><p>经过多层Transformer Encoder（自注意力机制+前馈网络）</p><p>最后用[CLS] token输出的向量进行分类</p><p>（CLS token是一个专门加在最前面的learnable向量，用来汇总全局信息</p><p>Encoder在ViT中的实现细节如下面代码所示（layer normalization -&gt; multi-head attention -&gt; drop path -&gt; layer normalization -&gt; mlp -&gt; drop path），换了个名字，叫block了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads, mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">False</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 drop_path=<span class="number">0.</span>, act_layer=nn.GELU, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 将每个样本的每个通道的特征向量做归一化</span></span><br><span class="line">        <span class="comment"># 也就是说每个特征向量是独立做归一化的</span></span><br><span class="line">        <span class="comment"># 我们这里虽然是图片数据，但图片被切割成了patch，用的是语义的逻辑</span></span><br><span class="line">        <span class="variable language_">self</span>.norm1 = norm_layer(dim)</span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> drop path for stochastic depth, we shall see if this is better than dropout here</span></span><br><span class="line">        <span class="variable language_">self</span>.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        <span class="variable language_">self</span>.norm2 = norm_layer(dim)</span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)</span><br><span class="line">        <span class="comment"># 全连接，激励，drop，全连接，drop,若out_features没填，那么输出维度不变。</span></span><br><span class="line">        <span class="variable language_">self</span>.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 最后一维归一化，multi-head attention, drop_path</span></span><br><span class="line">        <span class="comment"># (B, N, C) -&gt; (B, N, C)</span></span><br><span class="line">        x = x + <span class="variable language_">self</span>.drop_path(<span class="variable language_">self</span>.attn(<span class="variable language_">self</span>.norm1(x)))</span><br><span class="line">        <span class="comment"># (B, N, C) -&gt; (B, N, C)</span></span><br><span class="line">        x = x + <span class="variable language_">self</span>.drop_path(<span class="variable language_">self</span>.mlp(<span class="variable language_">self</span>.norm2(x)))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"> </span><br></pre></td></tr></table></figure><p>在ViT中这样的block会有好几层，形成blocks：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># stochastic depth decay rule</span></span><br><span class="line">dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, depth)]</span><br><span class="line"><span class="variable language_">self</span>.blocks = nn.Sequential(*[</span><br><span class="line">    Block(</span><br><span class="line">        dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate,</span><br><span class="line">        attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer, act_layer=act_layer)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br></pre></td></tr></table></figure><p>如果drop_path_rate大于0，每一层block的drop_path的会线性增加。depth是一个blocks里block的数量。也可以理解为blocks这个网络块的深度。</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer</title>
      <link href="/knowledgeNotes/2025/04/24/transformers/"/>
      <url>/knowledgeNotes/2025/04/24/transformers/</url>
      
        <content type="html"><![CDATA[<h2 id="Transformer整体结构">Transformer整体结构</h2><p><img src="/images/transformers.png" alt="Transformer模型详解（图解最完整版）" /></p><h3 id="注意力机制Attention">注意力机制Attention</h3><p>简单来说，注意力机制描述了（序列）元素的加权平均值，其权重是根据输入的query和元素的键值进行动态计算的，具体来讲，有4个概念要明确：</p><ul><li>Query：Query是一个特征向量，描述我们在序列中寻找什么，即我们可能想要注意什么</li><li>Keys：每个输入元素有一个键，它也是一个特征向量，该特征向量粗略的描述了该元素“提供”什么，或者他何时可能很重要，键的涉及应该使我们可以根据Query来识别我们想要关注的元素</li><li>Values：每个输入元素，我们还有一个值向量，这个向量就是我们想要平均的向量</li><li>Score function：评分函数，为了对想要关注的元素进行评分，我们需要指定要给评分函数f该函数将查询和键作为输入，并输出查询-键对的得分/注意力权重，它通常通过简单的相似性度量来实现，例如点积或MLP</li></ul><p>$$<br />\alpha_i = \frac{\exp\left( f_{\text{attn}}(\text{key}<em>i, \text{query}) \right)}<br />{\sum_j \exp\left( f</em>{\text{attn}}(\text{key}_j, \text{query}) \right)},<br />\quad<br />\text{out} = \sum_i \alpha_i \cdot \text{value}_i<br />$$</p><p>下图直观描述注意力如何作用在一系列单词上。对于每个单词，都有一个键和一个值向量。使用评分函数（在本例中为点积）将query与所有键进行比较以确定权重。最后，使用注意力权重对所有单词的值向量进行平均。（为了简单起见，softmax 没有可视化。）</p><p><img src="/images/how_qvk_cal.webp" alt="img" /></p><p>大多数注意力机制在使用哪些query、如何定义键、值向量，以及使用什么评分函数方面有所不同。</p><p>Transformer 架构内部应用的注意力称为<strong>自注意力（self-attention）</strong>。在自注意力中，每个序列元素提供一个键、值和query。对于每个元素，根据其query作用一个注意力神经层，检查所有序列元素键的相似性，并为每个元素返回一个不同的平均值向量。</p><h3 id="自注意力机制">自注意力机制</h3><p>自注意力背后的核心概念是缩放点积注意力（Scaled Dot Product Attention）。目标是建立一种注意力机制，序列中的任何元素都可以关注任何其他元素，同时仍能高效计算。</p><p>点积注意力将一组查询Q，键K和值V（三者矩阵尺寸为T*d，T为序列长度，d为查询、键或值的维度）。点积注意力的计算方法如下：</p><p>$$Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt d})V$$</p><p><img src="/images/self_attention.png" alt="Scaled Dot-Product Attention Explained | Papers With Code" /></p><h3 id="多头注意力机制">多头注意力机制</h3><p>缩放点积注意力让模型对一个序列进行“关注”。然而，序列元素通常需要关注多个不同方面，并且单个加权平均值并不是最佳选择。这就是提出多头注意力机制（Multi-Head Attention）的根源，即相同特征上的多个不同的（查询，键，值）三元组。</p><p>$$\text{Multihead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h) W^O<br />\ \text{where} \quad \text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$</p><p><img src="/images/multi_head_attention.png" alt="Multi-Head Attention Explained | Papers With Code" /></p><p>多头注意力的一个关键特征是它相对于输入具有置换同变性（permutation-equivariant）。因此，多头注意力实际上不是将输入视为序列，而是视为一组元素。这一特性使得多头注意力模块和 Transformer 架构适用广泛</p><h3 id="Transformer编码器">Transformer编码器</h3><p>最初，Transformer 模型是为机器翻译而设计的。它是一个编码器-解码器结构，其中编码器将原始语言的句子作为输入并生成基于注意力的表征。而解码器关注编码信息并以自回归方式生成翻译的句子，就像 RNN 一样</p><p>编码器由N个相同的模块组成，输入x首先通过上面提到的多头注意力块。使用残差连接将输出添加到原始输入，每一次都有归一化操作</p><p><img src="/images/encoder_decoder.png" alt="The Transformer: A Quick Run Through | by Mandar Deshpande | TDS Archive |  Medium" /></p><p>残差连接在 Transformer 架构中至关重要。</p><p>1、首先，与 ResNet类似，Transformers 层级很深。某些模型的编码器中包含超过 24 个blocks。因此，残差连接对于模型梯度的平滑流动至关重要。</p><p>2、如果没有残余连接，原始序列的信息就会丢失。多头注意力层忽略序列中元素的位置，并且只能根据输入特征来学习它。删除残余连接意味着该信息在第一个注意层之后（初始化之后）丢失，并且使用随机初始化的查询和键向量，位置i的输出向量与其原始输入无关。注意力的所有输出都可能表示相似/相同的信息，并且模型没有机会区分哪些信息来自哪个输入元素。</p><p>归一化层在 Transformer 架构中也发挥着重要作用，它可以实现更快的训练速度。</p><p>除了多头注意力之外，模型中还包括一个小型全连接前馈网络，应用于每一个block。它增加了模型的复杂度，并允许单独对每个序列元素进行转换。</p><p><img src="/images/detail_encoder_decoder.png" alt="BERT Model – Bidirectional Encoder Representations from Transformers -  QuantPedia" /></p><h2 id="Transformer-大致工作流">Transformer 大致工作流</h2><p>**第一步：**获取输入句子的每一个单词的表示向量 <strong>X</strong>，<strong>X</strong>由单词的 Embedding（Embedding就是从原始数据提取出来的Feature） 和单词位置的 Embedding 相加得到。</p><p><img src="/images/first_step_of_transformer.jpg" alt="img" /></p><p>**第二步：**将得到的单词表示向量矩阵 (如上图所示，每一行是一个单词的表示 <strong>x</strong>) 传入 Encoder 中，经过 6 个 Encoder block 后可以得到句子所有单词的编码信息矩阵 <strong>C</strong>，如下图。单词向量矩阵用 $$\mathbf{X}_{n×d} $$表示， n 是句子中单词个数，d 是表示向量的维度 (论文中 d=512)。每一个 Encoder block 输出的矩阵维度与输入完全一致。</p><p><img src="/images/the_second_step.jpg" alt="img" /></p><p><strong>第三步</strong>：将 Encoder 输出的编码信息矩阵 <strong>C</strong>传递到 Decoder 中，Decoder 依次会根据当前翻译过的单词 1~ i 翻译下一个单词 i+1，如下图所示。在使用的过程中，翻译到单词 i+1 的时候需要通过 <strong>Mask (掩盖)</strong> 操作遮盖住 i+1 之后的单词。</p><p><img src="/images/the_third_Step.jpg" alt="img" /></p><p>上图 Decoder 接收了 Encoder 的编码矩阵 <strong>C</strong>，然后首先输入一个翻译开始符 “<Begin>”，预测第一个单词 “I”；然后输入翻译开始符 “<Begin>” 和单词 “I”，预测单词 “have”，以此类推。这是 Transformer 使用时候的大致流程，接下来是里面各个部分的细节。</p><h2 id="Transformer-详细流程">Transformer 详细流程</h2><h3 id="单词Embedding和位置Embedding">单词Embedding和位置Embedding</h3><p>Transformer 中单词的输入表示 <strong>x</strong>由<strong>单词 Embedding</strong> 和<strong>位置 Embedding</strong> （Positional Encoding）相加得到。单词的 Embedding 有很多种方式可以获取，例如可以采用 Word2Vec、Glove 等算法预训练得到，也可以在 Transformer 中训练得到。Transformer 中除了单词的 Embedding，还需要使用位置 Embedding 表示单词出现在句子中的位置。**因为 Transformer 不采用 RNN 的结构，而是使用全局信息，不能利用单词的顺序信息，而这部分信息对于 NLP 来说非常重要。**所以 Transformer 中使用位置 Embedding 保存单词在序列中的相对或绝对位置。</p><p>位置 Embedding 用 <strong>PE</strong>表示，<strong>PE</strong> 的维度与单词 Embedding 是一样的。PE 可以通过训练得到，也可以使用某种公式计算得到。在 Transformer 中采用了后者，计算公式如下</p><p>$$PE_{(pos,2i)}=sin(pos/10000^{2i/d_model}) \ PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_model})$$</p><p>其中，pos 表示单词在句子中的位置，d 表示 PE的维度 (与词 Embedding 一样)，2i 表示偶数的维度，2i+1 表示奇数维度 (即 2i ≤ d, 2i+1 ≤ d)。使用这种公式计算 PE 有以下的好处：</p><ul><li>使 PE 能够适应比训练集里面所有句子更长的句子，假设训练集里面最长的句子是有 20 个单词，突然来了一个长度为 21 的句子，则使用公式计算的方法可以计算出第 21 位的 Embedding。</li><li>可以让模型容易地计算出相对位置，对于固定长度的间距 k，<strong>PE(pos+k)</strong> 可以用 <strong>PE(pos)</strong> 计算得到。因为 Sin(A+B) = Sin(A)Cos(B) + Cos(A)Sin(B), Cos(A+B) = Cos(A)Cos(B) - Sin(A)Sin(B)。</li></ul><p>将单词的词 Embedding 和位置 Embedding 相加，就可以得到单词的表示向量 <strong>x</strong>，<strong>x</strong> 就是 Transformer 的输入。</p><h3 id="Self-Attention">Self-Attention</h3><p><img src="/images/self_attention.jpg" alt="img" /></p><p>上图是论文中 Transformer 的内部结构图，左侧为 Encoder block，右侧为 Decoder block。红色圈中的部分为 <strong>Multi-Head Attention</strong>，是由多个 <strong>Self-Attention</strong>组成的，可以看到 Encoder block 包含一个 Multi-Head Attention，而 Decoder block 包含两个 Multi-Head Attention (其中有一个用到 Masked)。Multi-Head Attention 上方还包括一个 Add &amp; Norm 层，Add 表示残差连接 Residual Connection 用于防止网络退化，Norm 表示 Layer Normalization，用于对每一层的激活值进行归一化。</p><p><img src="D:%5Cblog%5Csource_posts%5Ctransformers.assets%5Cself_attention.png" alt="Scaled Dot-Product Attention Explained | Papers With Code" /></p><p>这是self-attention结构，在计算的时候需要用到矩阵Q(查询),K(键值),V(值)，在实际中，self-attention接收的是输入（单词的表示向量x组成的矩阵X）或者上一个Encoder block的输出，而QKV正是通过Self-Attention的输出线性变换得到的</p><h4 id="QKV的计算">QKV的计算</h4><p>Self-Attention 的输入用矩阵X进行表示，则可以使用线性变阵矩阵$$W^Q,W^K,W^V$$计算得到<strong>Q,K,V</strong>。计算如下图所示，<strong>注意 X, Q, K, V 的每一行都表示一个单词。</strong>，其中$$W^Q,W^K,W^V$$是随机初始的，再通过反向传播来优化的</p><p><img src="/images/qkv_calculation.jpg" alt="Frontiers | Research on prediction method of photovoltaic power generation  based on transformer model" /></p><p>得到矩阵 Q, K, V之后就可以计算出 Self-Attention 的输出了，计算的公式如下：</p><p>$$Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt d_k})V \quad  d_k是Q,K矩阵的列数，即向量维度$$</p><p>公式中计算矩阵<strong>Q</strong>和<strong>K</strong>每一行向量的内积，为了防止内积过大，因此除以 $$d_k $$的平方根。<strong>Q</strong>乘以<strong>K</strong>的转置后，得到的矩阵行列数都为 n，n 为句子单词数，这个矩阵可以表示单词之间的 attention 强度。下图为<strong>Q</strong>乘以 $$K^T$$ ，1234 表示的是句子中的单词。</p><p><img src="/images/calculation_of_qk.jpg" alt="img" /></p><p>得到$$QK^T $$之后，使用 Softmax 计算每一个单词对于其他单词的 attention 系数，公式中的 Softmax 是对矩阵的每一行进行 Softmax，即每一行的和都变为 1.</p><p><img src="/images/softmax_qk.jpg" alt="img" /></p><p>得到 Softmax 矩阵之后可以和<strong>V</strong>相乘，得到最终的输出<strong>Z</strong>。</p><p><img src="/images/self_attention_output.jpg" alt="img" /></p><p>上图中 Softmax 矩阵的第 1 行表示单词 1 与其他所有单词的 attention 系数，最终单词 1 的输出 $$Z_1$$ 等于所有单词 i 的值 $$V_i $$根据 attention 系数的比例加在一起得到，如下图所示</p><p><img src="/images/z_1_meaning.jpg" alt="img" /></p><h3 id="Multi-Head-Attention">Multi-Head Attention</h3><p>Multi-Head Attention 是由多个 Self-Attention 组合形成的，下图是论文中 Multi-Head Attention 的结构图。</p><p><img src="/images/multi_head_attention.jpg" alt="img" /></p><p>从上图可以看到 Multi-Head Attention 包含多个 Self-Attention 层，首先将输入<strong>X</strong>分别传递到 h 个不同的 Self-Attention 中，计算得到 h 个输出矩阵<strong>Z</strong>。下图是 h=8 时候的情况，此时会得到 8 个输出矩阵<strong>Z</strong>。</p><p><img src="/images/8_heads_of_multiple_head_attention.jpg" alt="img" /></p><p>得到 8 个输出矩阵 $$Z_1 到 Z_8 $$之后，Multi-Head Attention 将它们拼接在一起 <strong>(Concat)</strong>，然后传入一个<strong>Linear</strong>层，得到 Multi-Head Attention 最终的输出<strong>Z</strong></p><p><img src="/images/calculate_multi_head_output_Z.jpg" alt="img" /></p><p>可以看到 Multi-Head Attention 输出的矩阵<strong>Z</strong>与其输入的矩阵<strong>X</strong>的维度是一样的</p><h3 id="Encoder">Encoder</h3><p><img src="/images/encoder_structure.jpg" alt="img" /></p><p>上图红色部分是 Transformer 的 Encoder block 结构，可以看到是由 Multi-Head Attention, <strong>Add &amp; Norm, Feed Forward, Add &amp; Norm</strong> 组成的。刚刚已经了解了 Multi-Head Attention 的计算过程，现在了解一下 Add &amp; Norm 和 Feed Forward 部分。</p><h4 id="Add-Norm">Add &amp; Norm</h4><p>Add &amp; Norm 层由 Add 和 Norm 两部分组成，其计算公式如下</p><p>$%%%%%$$$LayerNorm(X+MultiHeadAttention(X)) \ LayerNorm(X+FeedForward(X))$$</p><p>其中X表示Multi-Head Attention或者FeedForward的输入，MultiHeadAttention(X)和Feedforward(X)表示输出，输入输出维度是一样的所以可以直接相加，<strong>Add</strong>指X+MultiHeadAttention(X)，是一种残差连接，通常用于解决多层网络训练的问题，可以让网络只关注当前差异部分，在ResNet中常用到<img src="/images/res_net_to_explain_residual.jpg" alt="img" /></p><p><strong>Norm</strong>指 Layer Normalization，通常用于 RNN 结构，Layer Normalization 会将每一层神经元的输入都转成均值方差都一样的，这样可以加快收敛。</p><h4 id="Feed-Forward">Feed Forward</h4><p>Feed Forward 层比较简单，是一个两层的全连接层，第一层的激活函数为 Relu，第二层不使用激活函数，对应的公式如下。$$max(0,XW_1+B_1)W_2+b_2$$    X是输入，Feed Forward最终得到的输出矩阵与维度X一致</p><h4 id="组成-Encoder">组成 Encoder</h4><p>通过上面描述的 Multi-Head Attention, Feed Forward, Add &amp; Norm 就可以构造出一个 Encoder block，Encoder block 接收输入矩阵$$ X_{(n×d)} ，并输出一个矩阵 O_{(n×d)}$$ 。通过多个 Encoder block 叠加就可以组成 Encoder。</p><p>第一个 Encoder block 的输入为句子单词的表示向量矩阵（是指加了positional embedding之后的），后续 Encoder block 的输入是前一个 Encoder block 的输出，最后一个 Encoder block 输出的矩阵就是<strong>编码信息矩阵 C</strong>，这一矩阵后续会用到 Decoder 中。</p><p><img src="/images/display_final_output_of_encoder.jpg" alt="img" /></p><h3 id="Decoder">Decoder</h3><p><img src="/images/Decoder_structure.jpg" alt="img" /></p><p>上图红色部分为 Transformer 的 Decoder block 结构，与 Encoder block 相似，但是存在一些区别：</p><ul><li>包含两个 Multi-Head Attention 层。</li><li>第一个 Multi-Head Attention 层采用了 Masked 操作。</li><li>第二个 Multi-Head Attention 层的<strong>K, V</strong>矩阵使用 Encoder 的<strong>编码信息矩阵C</strong>进行计算，而<strong>Q</strong>使用上一个 Decoder block 的输出计算。</li><li>最后有一个 Softmax 层计算下一个翻译单词的概率。</li></ul><h4 id="第一个Multi-Head-Attention">第一个Multi-Head Attention</h4><p>Decoder block的第一个Multi-Head Attention采用了Masked操作，因为在翻译的过程中是顺序翻译的，即翻译完第i个单词，才可以翻译第i+1个单词，通过Masked操作可以防止第i个单词知道i+1个单词之后的信息，下面以“我是一只猫”翻译成“I have a cat”为例</p><p>下面的描述中使用了类似 Teacher Forcing 的概念，不。在 Decoder 的时候，是需要根据之前的翻译，求解当前最有可能的翻译，如下图所示。首先根据输入 “<Begin>” 预测出第一个单词为 “I”，然后根据输入 “<Begin> I” 预测下一个单词 “have”。</p><p><img src="/images/decoder_predict.jpg" alt="img" /></p><p>Decoder 可以在训练的过程中使用 Teacher Forcing 并且并行化训练，即将正确的单词序列 (<Begin> I have a cat) 和对应输出 (I have a cat <end>) 传递到 Decoder。那么在预测第 i 个输出时，就要将第 i+1 之后的单词掩盖住，<strong>注意 Mask 操作是在 Self-Attention 的 Softmax 之前使用的，下面用 0 1 2 3 4 5 分别表示 “<Begin> I have a cat <end>”</strong></p><p>**第一步：**是 Decoder 的输入矩阵和 <strong>Mask</strong> 矩阵，输入矩阵包含 “<Begin> I have a cat” (0, 1, 2, 3, 4) 五个单词的表示向量，<strong>Mask</strong> 是一个 5×5 的矩阵。在 <strong>Mask</strong> 可以发现单词 0 只能使用单词 0 的信息，而单词 1 可以使用单词 0, 1 的信息，即只能使用之前的信息。<img src="/images/input_and_mask_matrix.jpg" alt="img" /></p><p><strong>第二步：<strong>接下来的操作和之前的 Self-Attention 一样，通过输入矩阵</strong>X</strong>计算得到<strong>Q,K,V</strong>矩阵。然后计算<strong>Q</strong>和 $$K^T 的乘积 QK^T $$。</p><p><img src="/images/Q_times_KT.jpg" alt="img" /></p><p><strong>第三步：<strong>在得到 $$QK^T$$ 之后需要进行 Softmax，计算 attention score，我们在 Softmax 之前需要使用</strong>Mask</strong>矩阵遮挡住每一个单词之后的信息，遮挡操作如下</p><p><img src="/images/the_second_mask.jpg" alt="img" /></p><p>得到 $$Mask QK^T 之后在 Mask QK^T$$上进行 Softmax，每一行的和都为 1。但是单词 0 在单词 1, 2, 3, 4 上的 attention score 都为 0。</p><p>**第四步：**使用 $$MaskQK^T$$与矩阵 <strong>V</strong>相乘，得到输出 <strong>Z</strong>，则单词 1 的输出向量 Z1 是只包含单词 1 信息的。</p><p><img src="/images/decoder_get_output_z.jpg" alt="img" /></p><p><strong>第五步：<strong>通过上述步骤就可以得到一个 Mask Self-Attention 的输出矩阵 $$Z_i$$ ，然后和 Encoder 类似，通过 Multi-Head Attention 拼接多个输出$$Z_i$$ 然后计算得到第一个 Multi-Head Attention 的输出</strong>Z</strong>，<strong>Z</strong>与输入<strong>X</strong>维度一样。</p><h4 id="第二个Multi-Head-Attention">第二个Multi-Head Attention</h4><p>Decoder block 第二个 Multi-Head Attention 变化不大， 主要的区别在于其中 Self-Attention 的 <strong>K, V</strong>矩阵不是使用 上一个 Decoder block 的输出计算的，而是使用 <strong>Encoder 的编码信息矩阵 C</strong> 计算的。</p><p>根据 Encoder 的输出 <strong>C</strong>计算得到 <strong>K, V</strong>，根据上一个 Decoder block 的输出 <strong>Z</strong> 计算 <strong>Q</strong> (如果是第一个 Decoder block 则使用输入矩阵 <strong>X</strong> 进行计算)，后续的计算方法与之前描述的一致。</p><p>这样做的好处是在 Decoder 的时候，每一位单词都可以利用到 Encoder 所有单词的信息 (这些信息无需 <strong>Mask</strong>)。</p><h3 id="Softmax-预测输出单词">Softmax 预测输出单词</h3><p>Decoder block 最后的部分是利用 Softmax 预测下一个单词，在之前的网络层我们可以得到一个最终的输出 Z，因为 Mask 的存在，使得单词 0 的输出 Z0 只包含单词 0 的信息，如下：</p><p><img src="/images/softmax_final_output.jpg" alt="img" /></p><p>Decoder Softmax 之前的 Z</p><p>Softmax 根据输出矩阵的每一行预测下一个单词：</p><p><img src="/images/softmax_output_2.jpg" alt="img" /></p><p>Decoder Softmax 预测</p><p>这就是 Decoder block 的定义，与 Encoder 一样，Decoder 是由多个 Decoder block 组合而成。</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多模态</title>
      <link href="/knowledgeNotes/2025/04/17/Multimodal/"/>
      <url>/knowledgeNotes/2025/04/17/Multimodal/</url>
      
        <content type="html"><![CDATA[<h2 id="定义">定义</h2><p>“模态”是指信息的表达方式，例如：</p><ul><li><strong>文本</strong>（Text）</li><li><strong>图像</strong>（Image）</li><li><strong>语音/音频</strong>（Audio）</li><li><strong>视频</strong>（Video）</li><li><strong>传感器数据</strong>（Sensor Data）</li></ul><p><strong>多模态系统</strong>就是指能同时处理并整合这些不同类型数据的系统，因为本次任务聚焦于文本和图像的多标签文本分类，所以下文将专注于从这两的实践来叙述</p><p>多模态学习涉及到多种关键技术，包括模态的<strong>表示、对齐、融合、转换</strong>以及协同学习等，这些技术有助于建立不同模态之间的对应关系，学习多模态的共享表征空间，以及利用各模态间的互补来增强语义互补</p><h2 id="对齐vs融合"><strong>对齐vs融合</strong></h2><p>对齐关注的是如何在不同模态之间建立对应关系，而融合则是关于如何将这些多模态信息有效地结合起来，以提高模型的性能</p><p>模态表示：模态表示是将不同感官或交互方式的数据转换为计算机可理解和处理的形式，以便后续的计算、分析和融合</p><p><strong>文本模态的表示方法</strong>：文本模态的表示方法有多种，如one-hot，低维空间表示（如通过神经网络模型学习得到的转换矩阵将单词或子映射到语义空间中）、词袋表示及其衍生出的n-grams词袋表示等。目前主流的文本表示方法是预训练文本模型如BERT,Word2Vec等</p><p><strong>视觉模态的表示</strong>：视觉模态分为图像模态和视频模态。图像模态的表示主要通过卷积神经网络（CNN）实现，如LeNet-5、AlexNet、VGG、GoogLeNet、ResNet等。视频模态的表示则结合了图像的空间属性和时间属性，通常由CNN和循环神经网络（RNN）或长短时记忆网络（LSTM）等模型共同处理。</p><p>**表征学习（Representation Learning）≈向量化（Embedding）**旨在从原始数据中自动提取有效特征，<em><strong>形成计算机可理解的模态表示</strong></em>，以保留关键信息并促进跨模态交互与融合。</p><h3 id="什么是多模态联合表示（Joint-Representation）？"><strong>什么是多模态联合表示（Joint Representation）？</strong></h3><p>多模态联合表示是一种将多个模态（如文本、图像、声音等）的信息<strong>共同映射到一个统一的多模态向量空间</strong>中的表示方法。</p><p>多模态联合表示通过神经网络、概率图模型将来自不同模态的数据进行融合，生成一个包含多个模态信息的统一表示。这个表示不仅保留了每个模态的关键信息，还能够在不同模态之间建立联系，从而支持跨模态的任务，如多模态情感分析、视听语音识别等</p><p><img src="/images/jointrepresentataion.png" alt="img" /></p><h3 id="什么是多模态协同表示（Coordinated-Representation）？"><strong>什么是多模态协同表示（Coordinated Representation）？</strong></h3><p>多模态协同表示是一种<strong>将多个模态的信息分别映射到各自的表示空间</strong>，但映射后的向量或表示之间需要<strong>满足一定的相关性或约束条件</strong>的方法。这种方法的核心在于确保不同模态之间的信息在协同空间内能够相互协作，共同优化模型的性能。</p><p><img src="/images/coordinatedrepresentation.png" alt="img" /></p><p><img src="/images/modalrepresentationComparsion.png" alt="image-20241004092412638" /></p><h3 id="联合表示vs协同表示"><strong>联合表示vs协同表示</strong></h3><blockquote><p>一个映射到统一的空间中，一个分别映射到各自空间，然后再建立联系/关联</p></blockquote><table><thead><tr><th>特点</th><th>说明</th></tr></thead><tbody><tr><td>表示融合</td><td>将模态A（如图像）和模态B（如文本）提取出的特征<strong>拼接/加权</strong>后送入同一个网络模块中</td></tr><tr><td>端到端训练</td><td>整个模型（图像编码器、文本编码器、融合层、分类头）可以<strong>一起训练</strong></td></tr><tr><td>表示维度匹配</td><td>通常需要将每个模态输出投影到<strong>相同维度</strong>再融合</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">图像 ---&gt; CNN ---&gt; <span class="number">256</span>维表示 --/</span><br><span class="line">                             &gt; concat --&gt; MLP --&gt; 输出</span><br><span class="line">文本 ---&gt; BERT --&gt; <span class="number">256</span>维表示 --/</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>协同表示（Coordinated Representation）</strong>。它是多模态学习中另一个核心思路，和联合表示相比，结构更<strong>松耦合</strong>，但目的更明确——<strong>保持不同模态之间语义上的一致性，同时保留各自独立表示空间</strong>。</p><table><thead><tr><th>特征</th><th>说明</th></tr></thead><tbody><tr><td><strong>保持独立</strong></td><td>图像、文本、音频等模态分别编码，不做 early fusion</td></tr><tr><td><strong>语义对齐</strong></td><td>用“距离函数”或“对比损失”来让不同模态表示趋于一致</td></tr><tr><td><strong>可扩展性强</strong></td><td>更适合跨模态检索、生成等任务</td></tr><tr><td><strong>常结合对比学习（Contrastive Learning）</strong></td><td>如 CLIP、ALIGN 等模型中广泛使用</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment">#协同表示的示例代码</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CoordinatedModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_encoder, txt_encoder</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.img_encoder = img_encoder</span><br><span class="line">        <span class="variable language_">self</span>.txt_encoder = txt_encoder</span><br><span class="line">        <span class="variable language_">self</span>.temp = nn.Parameter(torch.tensor(<span class="number">1.0</span>))  <span class="comment"># 可学习的温度参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, images, texts</span>):</span><br><span class="line">        img_feat = F.normalize(<span class="variable language_">self</span>.img_encoder(images), dim=-<span class="number">1</span>)</span><br><span class="line">        txt_feat = F.normalize(<span class="variable language_">self</span>.txt_encoder(texts), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        logits = img_feat @ txt_feat.T / <span class="variable language_">self</span>.temp</span><br><span class="line">        labels = torch.arange(images.size(<span class="number">0</span>)).to(images.device)</span><br><span class="line"></span><br><span class="line">        loss_i2t = F.cross_entropy(logits, labels)  <span class="comment"># 图→文</span></span><br><span class="line">        loss_t2i = F.cross_entropy(logits.T, labels)  <span class="comment"># 文→图</span></span><br><span class="line">        loss = (loss_i2t + loss_t2i) / <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"><span class="comment">#联合表示的示例代码</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiModalModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 图像编码器（使用预训练的 ResNet18）</span></span><br><span class="line">        <span class="variable language_">self</span>.image_encoder = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.image_encoder.fc = nn.Linear(<span class="number">512</span>, <span class="number">256</span>)  <span class="comment"># ✅ 将原始输出映射到256维向量（统一维度）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 文本编码器（使用预训练的 BERT）</span></span><br><span class="line">        <span class="variable language_">self</span>.text_encoder = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.text_proj = nn.Linear(<span class="number">768</span>, <span class="number">256</span>)  <span class="comment"># ✅ BERT 的输出是768维，我们也把它映射到256维</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 融合+分类器（典型的联合表示结构）</span></span><br><span class="line">        <span class="variable language_">self</span>.classifier = nn.Sequential(</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span> * <span class="number">2</span>, <span class="number">128</span>),  <span class="comment"># ✅ 图像和文本各256维，拼接后是512维</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">1</span>)  <span class="comment"># ✅ 输出一个数，用于二分类（可用 sigmoid）</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image, text_input</span>):</span><br><span class="line">        <span class="comment"># 图像编码：从 ResNet 得到图像的表征</span></span><br><span class="line">        img_feat = <span class="variable language_">self</span>.image_encoder(image)  <span class="comment"># (batch_size, 256)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 文本编码：从 BERT 得到文本的语义表示（pooler_output 是[CLS] token的输出）</span></span><br><span class="line">        text_feat = <span class="variable language_">self</span>.text_encoder(**text_input).pooler_output  <span class="comment"># (batch_size, 768)</span></span><br><span class="line">        text_feat = <span class="variable language_">self</span>.text_proj(text_feat)  <span class="comment"># ✅ 投影到256维</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ✅ 联合表示融合方式：直接拼接两个模态向量</span></span><br><span class="line">        fused = torch.cat([img_feat, text_feat], dim=<span class="number">1</span>)  <span class="comment"># (batch_size, 512)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分类输出</span></span><br><span class="line">        output = <span class="variable language_">self</span>.classifier(fused)  <span class="comment"># (batch_size, 1)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="多模态对齐">多模态对齐</h3><p>对齐是指在不同模态的数据之间<strong>发现和建立对应关系</strong>的过程</p><p><strong>显示对齐（Explicit Alignment）</strong></p><p>直接建立不同模态之间得对应关系，包括无监督对齐和监督对齐，显示对齐得一个重要工作是相似性度量，大多数方法都依赖于度量不同模态之间的相似性作为基本构建块。</p><p><em><strong>无监督对齐</strong></em>：利用数据本身得统计特性或结构信息，无需额外标签，<strong>自动发现不同模态间得对应关系</strong></p><ul><li>CCA（典型相关分析）：通过最大化两组变量之间的相关性来发现它们之间的线性关系，常用于图像和文本的无监督对齐。</li><li>自编码器：通过编码-解码结构学习数据的低维表示，有时结合循环一致性损失（Cycle Consistency Loss）来实现无监督的图像-文本对齐。</li></ul><p><em><strong>监督对齐</strong></em>：利用额外得标签或监督信息指导对齐过程，确保对齐得准确性</p><ul><li>多模态嵌入模型：如DeViSE(Deep Visual-Semantic Embeddings)通过最大化图像和对应文本标签在嵌入空间中得相似度来实现监督对齐</li><li>多任务学习模型：同时学习图像分类和文本生成任务，利用共享层或联合损失函数来促进图像和文本之间得监督对齐</li></ul><p><strong>隐式对齐（Implicit Alignment）</strong></p><p>隐式对齐<strong>用作另一个任务的中间(通常是潜在的)步骤。</strong> 这允许在许多任务中有更好的表现，包括语音识别、机器翻译、媒体描述和视觉问题回答。这些模型不显式地对齐数据，也不依赖于监督对齐示例，而是学习如何在模型训练期间潜在地对齐数据。不是直接建立对应关系，而是通过模型内部机制隐式地实现跨模态的对齐，这其中就包括<strong>注意力对齐和语义对齐</strong></p><ol><li>注意力对齐<ol><li>Transformer模型：在跨模态任务中（如图像描述生成），利用自注意力机制和编码器-解码器结构，自动学习图像和文本之间的注意力分布，实现隐式对齐</li><li>BERT-Based模型：在问答系统或文本-图像检索中，结合BERT的预训练表示和注意力机制，隐式地对齐文本查询和图像内容</li></ol></li><li>语义对齐<ol><li>图神经网络（GNN）：在构建图像和文本之间的语义时，利用GNN学习节点（模态数据）之间的语义关系，实现隐式的语义对齐</li><li>预训练语言模型与视觉模型结合：如CLIP(Contrastive Lanugage-Image Pre-training)，通过对比学习在大量图像-文本对上训练，使模型学习到图像和文本在语义层面的对应关系，实现高效的隐式语义对齐</li></ol></li></ol><h2 id="多模态融合">多模态融合</h2><p><strong>什么是多模态融合（MultiModal Fusion）？</strong></p><p>多模态融合指的是抽取自不同模态的信息整合成一个稳定的多模态表征，能够充分利用不同模态之间的互补性。从数据处理的层次角度将多模态融合分为<strong>数据级融合、特征级融合和目标级融合。</strong></p><p><img src="/images/multimodalfusion.png" alt="image-20241004093207042" /></p><ul><li><p>数据级融合（Data-Level Fusion）：</p><ul><li>数据级融合，也称为像素级融合或原始数据融合，是在最底层的数据级别上进行融合。<strong>这种融合方式通常发生在数据预处理阶段，即将来自不同模态的原始数据直接合并或叠加在一起，形成一个新的数据集。</strong></li><li>应用场景：适用于那些原始数据之间具有高度相关性和互补性的情况，如图像和深度图的融合。</li></ul></li><li><p>特征级融合（Feature-Level Fusion）：</p><ul><li>特征级融合是在特征提取之后、决策之前进行的融合。<strong>不同模态的数据首先被分别处理，提取出各自的特征表示，然后将这些特征表示在某一特征层上进行融合。</strong>==注：特征层是指网络中输出语义特征的那一层，代表模态的抽象表示==</li><li>应用场景：广泛应用于图像分类、语音识别、情感分析等多模态任务中。</li></ul></li><li><p>目标级融合（Decision-Level Fusion）：</p><ul><li>目标级融合，也称为决策级融合或后期融合，是在各个单模态模型分别做出决策之后进行的融合。每个模态的模型首先独立地处理数据并给出自己的预测结果（如分类标签、回归值等），然后将这些预测结果进行整合以得到最终的决策结果。</li><li>应用场景：适用于那些需要综合考虑多个独立模型预测结果的场景，如多传感器数据融合、多专家意见综合等。</li></ul></li></ul><p><img src="/images/differenttypeofmultimodal" alt="img" /></p><h2 id="协同学习Co-learning">协同学习Co-learning</h2><p>在模态的表示和他们的预测模型之间转移知识，协同学习探索了从一种模态中学习的知识如何帮助在不同模态上训练的的计算模型，当其中一种模式资源有限（例如，带注释的数据）这一挑战尤其重要，辅助模态通常只参与模型得训练，不参与模型的使用</p><p><img src="/images/colearning.png" alt="img" /></p><h3 id="并行">并行</h3><p>需要训练数据集，其中来自一种模态的观察结果与来自其他模态的观察结果直接相关，例如在一个视听语音数据集中，视频和语音样本来自同一个说话者。</p><h3 id="非并行">非并行</h3><p>不需要来自不同模式的观察结果之间的直接联系，通常通过使用类别重叠来实现共同学习，例如，在零样本学习中，使用来自Wikipedia的纯文本数据集扩展传统的视觉对象识别数据集以改进视觉对象识别的泛化能力。</p><h3 id="混合">混合</h3><p>通过共享模式或数据集桥接</p><p>参考资料：</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN</title>
      <link href="/knowledgeNotes/2025/04/16/RNN/"/>
      <url>/knowledgeNotes/2025/04/16/RNN/</url>
      
        <content type="html"><![CDATA[<h1>RNN</h1><p>Recurrent Neural Network是一种具有循环结构的神经网络，能够处理序列数据，与传统的前馈神经网络不同，RNN通过将当前时刻的输出与前一时刻的状态（或叫做隐藏层）作为输入传递到下一个时刻，使得它能保留之前的信息并用于当前的决策</p><p><img src="/images/1HgAY1lLMYSANqtgTgwWeXQ.png" alt="img" /></p><p><strong>输入层</strong>：输入数据的每一时刻（如时间序列数据的每个时间步）都会传递到网络</p><p><strong>隐藏层</strong>：RNN的核心是循环结构，它将先前的隐藏状态与当前的输入结合，生成当前的隐藏状态。通常，RNN的隐藏层包含多个神经元，且它们的状态是由上一时刻的输出状态递归计算得来的。</p><p><strong>输出层</strong>：基于隐藏层的输出，生成预测结果。</p><p>假设我们有输入序列 $$x_1,x_2,…,x_T$$，RNN 每个时间步 t 会更新隐藏状态 $$h_t$$，基本公式如下：</p><p>$$h_t=\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)$$</p><p>$$\hat y_t=W_{hy}h_t+b_y $$</p><p>其中的参数有：</p><ul><li>$$W_{xh}$$：输入到隐藏层的权重（输入维度 → 隐藏维度）</li><li>$$W_{hh}$$：隐藏状态之间的权重（隐藏维度 → 隐藏维度）</li><li>$$b_h$$：隐藏层的偏置</li><li>$$W_{hy}$$：隐藏到输出的权重（隐藏维度 → 输出维度）</li><li>$$b_y$$：输出层偏置</li></ul><p>RNN的种类有以下这些：</p><p>one-to-one：简单预测</p><p>one-to-many：图像描述生成</p><p>many-to-one：分类问题，比如说：情感分析，给定一段话，输出这段话的情况是positive还是negative</p><p>第一个many-to-many：机器翻译，语言模型</p><p>第二个many-to-many：命名实体识别（NER），词性标注（POS Tagging）</p><p><img src="/images/various_rnn.png" alt="various_rnn" /></p><h2 id="反向传播">反向传播</h2><p>RNN的反向传播(Backpropagation Through Time,BPTT)是它的核心部分，核心思路是展开时间维度做反向传播，由于RNN会在每个时间步共享参数，在做反向传播时要沿着时间轴展开整个网络</p><p>设loss为总损失: $$L=\sum_{t=1}^TL_t=\sum_{t=1}^TCrossEntropy(y_t,\hat y_t)$$</p><blockquote><p>这里算损失的时候对于每个时间步都去算了交叉熵，那这里每个时间步的true label到底是什么</p></blockquote><ul><li>情况一：每个时间步都要输出(多对多) 语言模型，机器翻译等任务，比如输入序列是x=[“I”,“love”,“deep”,“learning”]那么目标输出（true label）：y=[“love”,“deep”,“learning”,“!”] 那么对于每个时间步就有一个true label了</li><li>情况二：只有最后一个时间步需要输出（多对一）比如情感分析，输入一段话，最终只有一个结果，假设输入是x=[“This”,“movie”,“is”,“great”] 整个序列的输出只有一个y=“positive”，那么只在最后一步做交叉熵</li><li>情况三：同样是many-to-many，比如命名实体识别，词性标注，每个输入词都对应一个标签。输入句子： x=[“Barack”,“Obama”,“was”,“born”]目标标签：y=[“PER”,“PER”,“O”,“O”]每个时间步就有对应的真实标签。</li></ul><p><em>公式上进行了求和是因为我们假设的是 <strong>每个时间步都有输出、有标签</strong> 的任务，比如语言建模、机器翻译、时间序列预测等。如果是 <strong>只在最后一步才预测的任务</strong>，就不需要对每个时间步计算交叉熵，只计算最后一个时间步的损失就可以了。</em></p><p>对输出层的参数求导:</p><p>$$\frac{\partial L}{\partial W_{hy}}=\sum_{t=1}^T\frac{\partial L_t }{\partial  \hat y_t}\cdot \frac{\partial \hat y_t}{\partial W_{hy}}$$</p><p>根据上面对损失的分类讨论，这里的输出层的参数求导的求和也会根据上面的不同而不同，如上面每个时间步都有输出的语言模型，机器翻译，时间序列预测，就会有多个loss，所以就要对每个时间步求导，然后加总起来，形成最终的$$W_{hy}$$的梯度</p><p>对隐藏状态权重$$W_{hh}$$的梯度</p><p>$$\frac{\partial L}{\partial W_{hh}} = \sum_{t=1}^{T} \sum_{k=1}^{t}<br />\left(<br />\frac{\partial L_t}{\partial h_t} \cdot<br />\frac{\partial h_t}{\partial h_k} \cdot<br />\frac{\partial h_k}{\partial W_{hh}}<br />\right)$$</p><p>看懂这个式子很重要！</p><p>它的含义是：</p><ul><li>当前的损失$$L_t$$ 不仅受到当前的隐藏状态 $$h_t$$ 影响</li><li>$$h_t$$ 又受到之前所有隐藏状态 $$h_{t-1}, h_{t-2}, \dots$$ 的影响</li><li>所以梯度要“<strong>沿着时间向前传递</strong>”</li></ul><p>由于 $$W_{hh}$$ 是 <strong>在所有时间步中共享的参数</strong>，所以它的总梯度是所有时间步对它的影响的 <strong>累加</strong>$$\frac{\partial L}{\partial W_{hh}} = \sum_{t=1}^{T}\frac{\partial L_t}{\partial W_{hh}} $$==注：这里的求和也是 根据RNN的不同类型而做区别，只有多对多任务需要累加和，为了更通用，下面一律以多对多任务的情况进行最复杂的情况进行解释==</p><p>关键在于$$W_{hh}$$ 这里的$$L_t$$​对他求导，为了看着方便我们将前向传播的式子抄下来：$$h_t=\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)$$</p><p>$$\hat y_t=W_{hy}h_t+b_y $$</p><p>根据链式法则$$L_t=CrossEntropy(\hat y_t,y_t)$$ 所以根据链式法则， $$\frac{\partial L_t}{\partial h_t}$$ 然后$$h_t$$又是和$$W_{hh}$$是有关系了但要注意这里还有个$$h_{t-1}$$$$W_{hh}$$会间接受到多个时间步的影响，这一影响就是从头影响到结尾，所以对$$W_{hh}$$有了内层的求和，</p><p>同理对于$$W_{xh}$$的梯度更新：</p><p>对于每一个时间步都有</p><p>$$\frac{\partial h_t}{\partial W_{xh}}=(1−h_t^2)⋅x_t^⊤$$==注：这个求导结果是基于激活函数是tanh的情况下==</p><p>然后对于每个时间步产生的loss的对他的梯度$$\frac{\partial L_t}{\partial W_{xh}} = \frac{\partial L_t}{\partial h_t} \cdot \frac{\partial h_t}{\partial W_{xh}} = \delta_t \cdot x_t^\top$$</p><p>其中$$\delta_t = \frac{\partial L_t}{\partial h_t} \odot (1 - h_t^2)$$⊙ 表示按元素乘法（Hadamard product）。$$\delta_t$$来自输出层的梯度反传到$$h_t$$，</p><p>总梯度（因为$$W_{xh}$$在每个时间步也是共享的</p><p>$$\frac{\partial L}{\partial W_{xh}} = \sum_{t=1}^{T} \delta_t \cdot x_t^\top$$ ==每一项$$\delta_t \cdot x_t^\top$$都只和当前时间步$$x_t,h_t$$有关==</p><p>自此一次反向传播，再梯度下降更新参数，一次反向传播就全部完成了</p><h2 id="优缺点">优缺点</h2><h3 id="优点">优点</h3><h4 id="处理序列数据的天然优势">处理序列数据的天然优势</h4><ul><li>RNN 最大的优点是<strong>可以处理变长序列输入</strong>，不像传统的全连接神经网络（MLP）只能处理固定维度的向量。</li><li>它能自动建模时间步之间的<strong>时序依赖关系（temporal dependency）</strong>，这是做 NLP 和时间序列任务的基础。</li></ul><h4 id="参数共享，模型紧凑">参数共享，模型紧凑</h4><ul><li>RNN 在每个时间步<strong>共享相同的网络参数（权重）</strong>，不像深层 MLP 那样每一层都有一套参数。</li><li>这大大减少了模型的参数量，提升了<strong>泛化能力和训练效率</strong>。</li></ul><h3 id="缺点">缺点</h3><h4 id="梯度消失和梯度爆炸">梯度消失和梯度爆炸</h4><p>在训练 RNN 时采用 <strong>反向传播通过时间（BPTT）</strong>，梯度要链式传播多个时间步。</p><p>如果时间步较多，梯度会连续相乘：</p><p>$$\frac{\partial h_t}{\partial h_k} = \prod_{i=k+1}^{t} \frac{\partial h_i}{\partial h_{i-1}}$$</p><ul><li>导数小于 1 → 梯度消失，模型学不到长期依赖；</li><li>导数大于 1 → 梯度爆炸，导致模型不稳定或发散。</li></ul><p>这是 RNN 最大的训练困难之一。</p><h4 id="难以捕捉长期依赖关系">难以捕捉长期依赖关系</h4><ul><li>虽然理论上可以记住长期历史信息，但实际上 RNN 更擅长捕捉<strong>短期依赖</strong>。这里的本质原因还是梯度消失，反向传播的时候是相乘的，每乘一次梯度都会变小，长时间步乘下来就接近0即梯度消失，第二个就是RNN的结构只有一个隐藏状态$$h_t$$来记忆之前的信息，这个隐藏状态每一步都会被新的输入和权重洗掉，旧信息会被“覆盖”</li><li>长时间间隔的输入（如前文主语和后文动词）常常会被“遗忘”或削弱。</li><li>所以原始 RNN 不能很好地解决如语言建模中的“长句子”问题。</li></ul><h4 id="不能并行计算，训练效率低">不能并行计算，训练效率低</h4><ul><li>RNN 是<strong>严格按时间步串行计算</strong>的：必须等 $$h_{t-1}$$ 算出来后，才能计算 $$h_t$$。</li><li>这使得 <strong>GPU 加速效果不明显，训练时间长</strong>，尤其在长序列任务中更为明显。</li><li>相比之下，Transformer 是完全并行的，效率更高。</li></ul>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL41 最长连续登录天数</title>
      <link href="/problemNotes/2025/04/15/SQL41/"/>
      <url>/problemNotes/2025/04/15/SQL41/</url>
      
        <content type="html"><![CDATA[<h1>SQL41 最长连续登录天数</h1><h2 id="描述">描述</h2><p>你正在搭建一个用户活跃度的画像，其中一个与活跃度相关的特征是“最长连续登录天数”， 请用SQL实现“2023年1月1日-2023年1月31日用户最长的连续登录天数”</p><p>登陆表 <strong>tb_dau：</strong></p><table><thead><tr><th>fdate</th><th>user_id</th></tr></thead><tbody><tr><td>2023-01-01</td><td>10000</td></tr><tr><td>2023-01-02</td><td>10000</td></tr><tr><td>2023-01-04</td><td>10000</td></tr></tbody></table><p>输出：</p><table><thead><tr><th>user_id</th><th>max_consec_days</th></tr></thead><tbody><tr><td>10000</td><td>2</td></tr></tbody></table><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> tb_dau;</span><br><span class="line"><span class="keyword">create table</span> `tb_dau` (</span><br><span class="line">    `fdate` <span class="type">date</span>,</span><br><span class="line">    `user_id` <span class="type">int</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">insert into</span> tb_dau(fdate, user_id)</span><br><span class="line"><span class="keyword">values</span> </span><br><span class="line">(<span class="string">&#x27;2023-01-01&#x27;</span>, <span class="number">10000</span>),</span><br><span class="line">(<span class="string">&#x27;2023-01-02&#x27;</span>, <span class="number">10000</span>),</span><br><span class="line">(<span class="string">&#x27;2023-01-04&#x27;</span>, <span class="number">10000</span>);</span><br><span class="line">user_id<span class="operator">|</span>max_consec_days</span><br><span class="line"><span class="number">10000</span><span class="operator">|</span><span class="number">2</span></span><br></pre></td></tr></table></figure><blockquote><p>MySQL中日期加减的函数<br />日期增加 DATE_ADD，例：date_add(‘2023-01-01’, interval 1 day) 输出 ‘2023-01-02’<br />日期减少 DATE_SUB，例：date_sub(‘2023-01-01’, interval 1 day) 输出 ‘2022-12-31’<br />日期差 DATEDIFF，例：datediff(‘2023-02-01’, ‘2023-01-01’) 输出31</p></blockquote><h2 id="答案">答案</h2>]]></content>
      
      
      <categories>
          
          <category> problemNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>因果推断</title>
      <link href="/knowledgeNotes/2025/04/14/causal-inference/"/>
      <url>/knowledgeNotes/2025/04/14/causal-inference/</url>
      
        <content type="html"><![CDATA[<h1>因果推断</h1><h2 id="因果阶梯：">因果阶梯：</h2><ol><li>Association P(y|X)</li><li>how seeing X</li></ol><h2 id="Simpson’s-Paradox-辛普森悖论">Simpson’s Paradox(辛普森悖论)</h2><p>揭示了<strong>聚合数据</strong>和<strong>分组数据</strong>之间可能存在方向相反的结论</p><p>当对不同子组分别进行分析时，一个趋势是存在的，但当将这些子组数据<strong>合并</strong>后，趋势可能<strong>消失或反转</strong>。</p><p>产生的原因： 人群分布在混淆变量上不一致，导致相关关系完全可以被扭曲</p><p>解决的方式：取决于因果图，forks的话要分层，collider的话就不要分层</p><h3 id="Ex1-：UC-Berkeley-gender-bias">Ex1 ：UC Berkeley gender bias.</h3><p>Graduate admissions to UC Berkeley(Fall 1973)</p><p>​University-level Data</p><table><thead><tr><th></th><th>Men</th><th></th><th>Women</th><th></th></tr></thead><tbody><tr><td></td><td>Applicants</td><td>Admitted</td><td>Applicants</td><td>Admitted</td></tr><tr><td>Total</td><td>8442</td><td>44%</td><td>4321</td><td>35%</td></tr></tbody></table><p>-&gt;  University-level data shows bias in favor of men</p><p>​Department level Data</p><table><thead><tr><th>Department</th><th>MEN</th><th></th><th>women</th><th></th></tr></thead><tbody><tr><td></td><td>Applicants</td><td>Admitted</td><td>Applicants</td><td>Admitted</td></tr><tr><td>A</td><td>825</td><td>62%</td><td>108</td><td>82%</td></tr><tr><td>B</td><td>560</td><td>63%</td><td>25</td><td>68%</td></tr><tr><td>C</td><td>325</td><td>37%</td><td>593</td><td>34%</td></tr><tr><td>D</td><td>417</td><td>33%</td><td>375</td><td>35%</td></tr><tr><td>E</td><td>191</td><td>28%</td><td>393</td><td>24%</td></tr><tr><td>F</td><td>373</td><td>6%</td><td>341</td><td>7%</td></tr></tbody></table><p>-&gt;  Department-level data shows bias in favor of women</p><h3 id="Ex2-Treatment-Effect">Ex2: Treatment Effect</h3><p>-&gt; Subpopulation data:</p><p>​Men</p><table><thead><tr><th></th><th>Not recovered</th><th>recovered</th><th>TOTAL</th></tr></thead><tbody><tr><td>Treat</td><td>6</td><td>81</td><td>87</td></tr><tr><td>No Treat</td><td>36</td><td>234</td><td>270</td></tr></tbody></table><p>P(Recovered|Treat)=81/87=0.93  ①</p><p>P(Recovered|No Treat)=234/270=0.87 ②</p><p>​Women</p><table><thead><tr><th></th><th>Not recovered</th><th>recovered</th><th>TOTAL</th></tr></thead><tbody><tr><td>Treat</td><td>71</td><td>192</td><td>263</td></tr><tr><td>No Treat</td><td>25</td><td>55</td><td>80</td></tr></tbody></table><p>P(Recovered|Treat)=192/263=0.73  ③</p><p>P(Recovered|No Treat)=55/80=0.69 ④</p><p>-&gt;Population Data:</p><table><thead><tr><th></th><th>Not recovered</th><th>recovered</th><th>TOTAL</th></tr></thead><tbody><tr><td>Treat</td><td>77</td><td>273</td><td>350</td></tr><tr><td>No Treat</td><td>61</td><td>289</td><td>350</td></tr></tbody></table><p>P(Recovered|Treat)=273/350=0.78 A</p><p>P(Recovered|No Treat)=289/350=0.83 B</p><p>what we observe is on the population data -&gt; A&lt;B</p><p>but on the subpopulation data -&gt; Men ①&gt;②; Women ③&gt;④</p><p>paradox: The data says if the gender is known, we consider that treatment has effect, but if the gender is unknown, the treatment doesn’t work.</p><table><thead><tr><th></th><th>X</th><th>Y</th><th>Z</th></tr></thead><tbody><tr><td>0</td><td>women</td><td>Not Recovered</td><td>No Treat</td></tr><tr><td>1</td><td>men</td><td>Recovered</td><td>Treat</td></tr></tbody></table><p>subpopulation data:</p><table><thead><tr><th>Men(X=1)</th><th></th><th>eSTIMATE PROBABILITY</th><th></th></tr></thead><tbody><tr><td>Treat(Z=1)</td><td>P(Y=1|X=1,Z=1)=0.93</td><td>①</td><td></td></tr><tr><td>NOT Treat(Z=0)</td><td>P(Y=1|X=1,Z=0)=0.87</td><td>②</td><td></td></tr></tbody></table><table><thead><tr><th>WOMEN(X=0)</th><th></th><th>eSTIMATE PROBABILITY</th><th></th></tr></thead><tbody><tr><td>Treat(Z=1)</td><td>P(Y=1|X=0,Z=1)=0.73</td><td>③</td><td></td></tr><tr><td>NOT Treat(Z=0)</td><td>P(Y=1|X=0,Z=0)=0.69</td><td>④</td><td></td></tr></tbody></table><table><thead><tr><th></th><th></th><th>eSTIMATE PROBABILITY</th><th></th></tr></thead><tbody><tr><td>Treat(Z=1)</td><td>P(Y=1|Z=1)=0.78</td><td>A</td><td></td></tr><tr><td>NOT Treat(Z=0)</td><td>P(Y=1|Z=0)=0.83</td><td>B</td><td></td></tr></tbody></table><p>P(Y=1|Z=1)=P(Y=1|X=1,Z=1)P(X=1|Z=1)+P(Y=1|X=0,Z=1)P(X=0|Z=1)</p><p>P(Y=1|Z=0)=P(Y=1|X=1,Z=0)P(X=1|Z=0)+P(Y=1|X=0,Z=0)P(X=0|Z=0)</p><p>令P(X=1|Z=1) 为q 则P(X=0|Z=1)为(1-q) $q\in(0,1)$</p><p>令P(X=1|Z=0) 为$q’$ 则P(X=0|Z=0)为(1-q’) $q’\in(0,1)$</p><p>则 A=①q+③(1-q) $q\in(0,1)$</p><p>B=②q’+④(1-q’) $q’\in(0,1)$</p><p>要使结果出现A&lt;B的情况：</p><ol><li><p>(1-q)的值大导致A的值趋向于③，是比①小的，从而导致了一个较小的A，同时(1-q)=P(X=0|Z=1)是个条件概率是讲治疗的人里面女性的概率，它大说明大多数的治疗的人是女性</p></li><li><p>同时①&lt;③，即女性无论治疗不治疗恢复都要比男性差</p></li></ol><p>同时满足这两个条件才可能出现反转的效果，即性别即会影响是否去治疗，同时也影响恢复情况</p><img src="causal-inference/image-20250414231146818.png"><h3 id="Ex3：">Ex3：</h3><p>给1500人用TreatmentA，550人用B看致死率，但本身病人的情况有轻重之分</p> <img src="causal-inference/CI_basic_1.png"><p>现象：subpopulation之后结论是B致死率更高，但是total的时候是A更好</p><p>造成的原因是unequal weighting：重症的人得到了更多得B，导致B看起来效果不好了⇒总体得结论是一个有偏的加权平均</p><ul><li>Treatment A的致死率计算里面，轻症的致死率全重大，所以致死率小</li><li>Treatment B的致死率计算里面，重症的致死率全重大，所以致死率大</li></ul><p>正确的解释：Either treatment A or treatment B could be the right answer, depending on 数据的因果结构!</p><ul><li>condition is a cause of the treatment</li></ul><div style="display: flex; justify-content: center; gap: 20px;">  <img src="causal-inference/CI_basic_2.png" style="max-width: 45%;">  <img src="causal-inference/CI_basic_3.png" style="max-width: 45%;"></div><p>​比如医生把B专门用在重症，轻症的给A就行</p><p>​选择：这种情况要选B，看（subpopulation的结论，因为我们B中的高致死率知识因为本身就有很高的致死率里面有很多的重症</p><ul><li>treatment is a cause of the condition</li></ul><div style="display: flex; justify-content: center; gap: 20px;">  <img src="causal-inference/CI_basic_4.png" style="max-width: 45%;">  <img src="causal-inference/CI_basic_5.png" style="max-width: 45%;"></div><ul><li>解释：比如如果Treatment B，必须要等很久才能take，所以在等的时候condition会worsen——变成了重症！从而导致了更多的重症被接受了Treatment B. Treatment A不用等所以马上就轻症了！这就是为什么A的轻症占比更高</li><li>选择：这种情况要选A（看total的结论），因为Treatment本身是造成worse condition的原因，从而导致了Y。所以我们需要考虑T对C的影响而不能直接看conditional的结论（因为T会让你去不同的C！）</li></ul><p>考虑这个影响的办法就是直接看T对Y的总体效果。</p><p>结论：conclusion取决于causal structure</p><h2 id="统计基础知识点">统计基础知识点</h2><p>Independence: P(A∩B)=P(A)⋅P(B)</p><p>P(A|B) = P(A) 即当A与B独立，则已知B发生A发生的概率就是A本身发生的概率，他们的发生不会互相影响</p><p>condition independence: P(A|B,C)=P(A|C)</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A/B Test</title>
      <link href="/knowledgeNotes/2025/04/14/A-B-test/"/>
      <url>/knowledgeNotes/2025/04/14/A-B-test/</url>
      
        <content type="html"><![CDATA[<h1>A/B testing</h1><h2 id=""></h2>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL44 查询连续入住多晚的客户信息？</title>
      <link href="/problemNotes/2025/04/12/SQL44/"/>
      <url>/problemNotes/2025/04/12/SQL44/</url>
      
        <content type="html"><![CDATA[<h1>SQL44查询连续入住多晚的客户信息？</h1><h2 id="描述">描述</h2><p>某酒店客房信息数据及某晚入住信息数据如下：</p><p>客房信息表<strong>guestroom_tb</strong>(room_id-房间号,room_type-房间类型,room_price-房间价格)，如下所示：</p><table><thead><tr><th>room_id</th><th>room_type</th><th>room_price</th></tr></thead><tbody><tr><td>1001</td><td>商务标准房</td><td>165</td></tr><tr><td>1002</td><td>家庭套房</td><td>376</td></tr><tr><td>1003</td><td>商务单人房</td><td>100</td></tr><tr><td>1004</td><td>商务单人房</td><td>100</td></tr><tr><td>1005</td><td>商务标准房</td><td>165</td></tr><tr><td>1006</td><td>商务单人房</td><td>100</td></tr><tr><td>1007</td><td>商务标准房</td><td>165</td></tr><tr><td>1008</td><td>家庭套房</td><td>365</td></tr><tr><td>1009</td><td>商务标准房</td><td>165</td></tr></tbody></table><p>入住信息表<strong>checkin_tb</strong>(info_id-信息id.room_id-房间号,user_id-客户id,checkin_time-入住时间,checkout_time-退房时间)，</p><p>该表存储该晚客户入住信息及后续退房信息，如下所示：</p><table><thead><tr><th>info_id</th><th>room_id</th><th>user_id</th><th>checkin_time</th><th>checkout_time</th></tr></thead><tbody><tr><td>1</td><td>1001</td><td>201</td><td>2022-06-12 15:00:00</td><td>2022-06-13 09:00:00</td></tr><tr><td>2</td><td>1001</td><td>202</td><td>2022-06-12 15:00:00</td><td>2022-06-13 09:00:00</td></tr><tr><td>3</td><td>1003</td><td>203</td><td>2022-06-12 14:00:00</td><td>2022-06-14 08:00:00</td></tr><tr><td>4</td><td>1004</td><td>204</td><td>2022-06-12 15:00:00</td><td>2022-06-13 11:00:00</td></tr><tr><td>5</td><td>1007</td><td>205</td><td>2022-06-12 16:00:00</td><td>2022-06-15 12:00:00</td></tr><tr><td>6</td><td>1008</td><td>206</td><td>2022-06-12 19:00:00</td><td>2022-06-13 12:00:00</td></tr><tr><td>7</td><td>1008</td><td>207</td><td>2022-06-12 19:00:00</td><td>2022-06-13 12:00:00</td></tr><tr><td>8</td><td>1009</td><td>208</td><td>2022-06-12 20:00:00</td><td>2022-06-16 09:00:00</td></tr></tbody></table><p>问题：请查询该酒店从6月12日开始连续入住多晚的客户信息？</p><p>要求输出：客户id、房间号、房间类型、连续入住天数（按照连续入住天数的升序排序，再按照房间号的升序排序，再按照客户id的降序排序）</p><p>示例数据结果如下：</p><table><thead><tr><th>user_id</th><th>room_id</th><th>room_type</th><th>days</th></tr></thead><tbody><tr><td>203</td><td>1003</td><td>商务单人房</td><td>2</td></tr><tr><td>205</td><td>1007</td><td>商务标准房</td><td>3</td></tr><tr><td>208</td><td>1009</td><td>商务标准房</td><td>4</td></tr></tbody></table><p>解释：以客户203为例，在2022-06-12入住酒店，在2022-06-14退房，连续在12日晚、13日晚入住在该酒店，故结果如上；其他结果同理。</p><p>示例输入：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span>  `guestroom_tb` ; </span><br><span class="line"><span class="keyword">CREATE TABLE</span> `guestroom_tb` (</span><br><span class="line">`room_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`room_type` <span class="type">varchar</span>(<span class="number">16</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`room_price` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line"><span class="keyword">PRIMARY KEY</span> (`room_id`));</span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1001</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1002</span>,<span class="string">&#x27;家庭套房&#x27;</span>,<span class="number">376</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1003</span>,<span class="string">&#x27;商务单人房&#x27;</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1004</span>,<span class="string">&#x27;商务单人房&#x27;</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1005</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1006</span>,<span class="string">&#x27;商务单人房&#x27;</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1007</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1008</span>,<span class="string">&#x27;家庭套房&#x27;</span>,<span class="number">365</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> guestroom_tb <span class="keyword">VALUES</span>(<span class="number">1009</span>,<span class="string">&#x27;商务标准房&#x27;</span>,<span class="number">165</span>); </span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span>  `checkin_tb` ; </span><br><span class="line"><span class="keyword">CREATE TABLE</span> `checkin_tb` (</span><br><span class="line">`info_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`room_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`user_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span>,</span><br><span class="line">`checkin_time` datetime <span class="keyword">NOT NULL</span>,</span><br><span class="line">`checkout_time` datetime <span class="keyword">NOT NULL</span>,</span><br><span class="line"><span class="keyword">PRIMARY KEY</span> (`info_id`));</span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">1</span>,<span class="number">1001</span>,<span class="number">201</span>,<span class="string">&#x27;2022-06-12 15:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 09:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">2</span>,<span class="number">1001</span>,<span class="number">202</span>,<span class="string">&#x27;2022-06-12 15:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 09:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">3</span>,<span class="number">1003</span>,<span class="number">203</span>,<span class="string">&#x27;2022-06-12 14:00:00&#x27;</span>,<span class="string">&#x27;2022-06-14 08:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">4</span>,<span class="number">1004</span>,<span class="number">204</span>,<span class="string">&#x27;2022-06-12 15:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 11:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">5</span>,<span class="number">1007</span>,<span class="number">205</span>,<span class="string">&#x27;2022-06-12 16:00:00&#x27;</span>,<span class="string">&#x27;2022-06-15 12:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">6</span>,<span class="number">1008</span>,<span class="number">206</span>,<span class="string">&#x27;2022-06-12 19:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 12:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">7</span>,<span class="number">1008</span>,<span class="number">207</span>,<span class="string">&#x27;2022-06-12 19:00:00&#x27;</span>,<span class="string">&#x27;2022-06-13 12:00:00&#x27;</span>); </span><br><span class="line"><span class="keyword">INSERT INTO</span> checkin_tb <span class="keyword">VALUES</span>(<span class="number">8</span>,<span class="number">1009</span>,<span class="number">208</span>,<span class="string">&#x27;2022-06-12 20:00:00&#x27;</span>,<span class="string">&#x27;2022-06-16 09:00:00&#x27;</span>);</span><br></pre></td></tr></table></figure><p>答案</p><p>这道题对我的难点在于，在group by的时候，想要输出哪些列group by的时候就要写哪些，我这里用group by是因为我怕同一个顾客有多次入住记录，比如用户201他在6月12日有过入住记录，如果它6月15号还有入住记录，这时候就需要有区别。</p><p><code>DATE(ct.checkin_time) = '2022-06-12'</code>：选择在2022年6月12日入住的记录。<code>DATEDIFF(ct.checkout_time, ct.checkin_time) &gt;= 2</code>：选择连续入住至少两晚的记录（注意不要在where直接使用days&gt;= 2）。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id,</span><br><span class="line">    g.room_id,</span><br><span class="line">    room_type,</span><br><span class="line">    <span class="keyword">day</span> (checkout_time) <span class="operator">-</span> <span class="keyword">day</span> (checkin_time) <span class="keyword">as</span> days</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            user_id,</span><br><span class="line">            c.room_id,</span><br><span class="line">            checkin_time,</span><br><span class="line">            checkout_time</span><br><span class="line">        <span class="keyword">from</span></span><br><span class="line">            checkin_tb <span class="keyword">as</span> c</span><br><span class="line">        <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">            user_id,</span><br><span class="line">            c.room_id,</span><br><span class="line">            checkin_time,</span><br><span class="line">            checkout_time</span><br><span class="line">    ) temp</span><br><span class="line">    <span class="keyword">inner</span> <span class="keyword">join</span> guestroom_tb <span class="keyword">as</span> g <span class="keyword">on</span> g.room_id <span class="operator">=</span> temp.room_id</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    <span class="type">DATE</span> (temp.checkin_time) <span class="operator">&gt;=</span> <span class="string">&#x27;2022-06-12&#x27;</span></span><br><span class="line">    <span class="keyword">and</span> <span class="keyword">day</span> (checkout_time) <span class="operator">-</span> <span class="keyword">day</span> (checkin_time) <span class="operator">&gt;</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    days,</span><br><span class="line">    g.room_id,</span><br><span class="line">    user_id <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>题解代码</p><p>注意使用DATEDIFF函数，然后where语句不能直接使用days来做判断条件，但是我觉得题解这里没有解决同一个顾客如果有多条记录的情况怎么解决</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    ct.user_id,</span><br><span class="line">    ct.room_id,</span><br><span class="line">    gt.room_type,</span><br><span class="line">    DATEDIFF(ct.checkout_time, ct.checkin_time) <span class="keyword">AS</span> days</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    checkin_tb ct</span><br><span class="line"><span class="keyword">JOIN</span> </span><br><span class="line">    guestroom_tb gt <span class="keyword">ON</span> gt.room_id <span class="operator">=</span> ct.room_id</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">   <span class="type">DATE</span>(ct.checkin_time) <span class="operator">=</span> <span class="string">&#x27;2022-06-12&#x27;</span> <span class="keyword">AND</span> DATEDIFF(ct.checkout_time, ct.checkin_time) <span class="operator">&gt;=</span> <span class="number">2</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span></span><br><span class="line">    days <span class="keyword">ASC</span>, ct.room_id <span class="keyword">ASC</span>, ct.user_id <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> problemNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The First Blog</title>
      <link href="/knowledgeNotes/2025/04/12/my-first-blog/"/>
      <url>/knowledgeNotes/2025/04/12/my-first-blog/</url>
      
        <content type="html"><![CDATA[<h1>The first blog</h1><p>时间开始于2025/4/12，周六，晚上20:45，终于千难万险将所有前期准备弄完了！接下来我会定期将自己的学习笔记跟新在这里，一方面督促自己努力学习，同时将脑中知识整理成可以发布出去的版本！</p><h2 id="简介">简介</h2><p>嗯。。。简单介绍一下自己，我是一名悉大的学生Jasper，正在学习Data Science，但目前的就业情况呢，导致我这种学历的人呢，上不上，下不下的，所以我想以博客的形式督促增加自己的技能点，点亮所有必要的知识点，目前呢自己的状态就是啥都会一点，但是啥都不是那么会，包括最基础的Python/SQL/R，Machine Learning，Deep Learning，作为一个计算机科班出生的，Java自然也不在话下，算法嘛会点，但绝对不多，大数据框架Hadoop好像是学完了，但好像又没有，Hive，Spark现在还在学习中</p><p>最后用看到张一鸣说过的一句话来结尾</p><p>做正确的事才是务实，短期投机不是务实。大力出奇迹事务实，刨根问底是务实，抓住本之是务实，尊重用户是务实，认识世界的多样性是务实。</p>]]></content>
      
      
      <categories>
          
          <category> knowledgeNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
